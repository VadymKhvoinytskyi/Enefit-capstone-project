{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Submission Notebook\n","## Preparing and Merging Train Data"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import plotly.express as px\n","\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["# crucial for import API interface and loading data\n","ON_KAGGLE: bool = False\n","\n","if ON_KAGGLE:\n","    DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\n","else:\n","    DATA_DIR = \"../data/\"\n","\n","# Read CSVs and parse relevant date columns\n","train = pd.read_csv(DATA_DIR + \"train.csv\")\n","client = pd.read_csv(DATA_DIR + \"client.csv\")\n","historical_weather = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\n","forecast_weather = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\n","electricity_prices = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\n","gas_prices = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\n","weather_station_to_county_mapping = pd.read_csv(DATA_DIR + 'weather_station_to_county_mapping.csv')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Datetime conversion\n"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["client.date = pd.to_datetime(client.date)\n","\n","electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n","electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n","\n","forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n","forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n","\n","gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n","gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n","\n","historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n","\n","train.datetime = pd.to_datetime(train.datetime, format='%Y-%m-%d %H:%M:%S')"]},{"cell_type":"markdown","metadata":{},"source":["# Merging historical data"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["# append '_client' to merged columns\n","client.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]\n","\n","# merge train and client\n","merged_df = pd.merge(train, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n","\n","\n","# append _gas_prices to columns\n","gas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]\n","\n","# merge gas_prices\n","merged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n","\n","\n","# add time column for merging with electricity data\n","merged_df['time_of_day'] = merged_df['datetime'].dt.time\n","\n","# the prices are available hourly -> create new column with time \n","electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n","\n","# append electricity_prices to column names\n","electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n","\n","# merge electricity_prices\n","merged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n","\n","\n","# get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n","# round lat and long to avoid mismatching due to different accuracy\n","historical_weather.latitude = historical_weather.latitude.round(1)\n","historical_weather.longitude = historical_weather.longitude.round(1)\n","\n","weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\n","weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n","\n","\n","# merge historical weather to get counties\n","merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","\n","# get time of day\n","merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n","\n","# aggregate by county and time (summarize weather stations for same county)\n","merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n","\n","# append _hist_weather to column names\n","merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n","\n","# merge to merged_df\n","merged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')\n","\n","\n","#round lat and long\n","forecast_weather.latitude = forecast_weather.latitude.round(1)\n","forecast_weather.longitude = forecast_weather.longitude.round(1)\n","\n","# merge to get counties\n","merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","# merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n","\n","# # aggregate for duplicate locations\n","merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n","\n","# append forecast_weather to column names\n","merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n","\n","# merge forecast_weather\n","merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime', 'county'], right_on=['data_block_id', 'forecast_datetime', 'county'], how='left')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Data Preparation"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[],"source":["def split_datetime(data, col=\"datetime\"):\n","    # What columns are of type datetime?\n","    datetime_columns = data.select_dtypes(include='datetime64').columns\n","    \n","    for c in datetime_columns:\n","        # print(f\"Timezone for {c} is {data[c].dt.tz}\")\n","        pass\n","\n","    # Adding columns for date & time\n","    data['year']    = data[col].dt.year\n","    # data['quarter'] = data[col].dt.quarter\n","    data['month']   = data[col].dt.month\n","    data['week']    = data[col].dt.isocalendar().week\n","    data['hour']    = data[col].dt.hour \n","\n","    data['day_of_year']  = data[col].dt.day_of_year\n","    data['day_of_month'] = data[col].dt.day\n","    data['day_of_week']  = data[col].dt.day_of_week\n","\n","    return data"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["# mapping days of the week names and converting to categorical variable\n","if 'day_of_week' in merged_df.columns:\n","    weekday_map = {\n","        0: 'Monday',\n","        1: 'Tuesday',\n","        2: 'Wednesday',\n","        3: 'Thursday',\n","        4: 'Friday',\n","        5: 'Saturday',\n","        6: 'Sunday'\n","    }\n","    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["# encode categories to category datetype\n","\n","merged_df['county'] = merged_df['county'].astype('category')\n","merged_df['product_type'] = merged_df['product_type'].astype('category')\n"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["# copy df for modelling\n","model_df = merged_df\n","\n","# model is not able to handle object type\n","model_df.drop('time_of_day', axis=1, inplace=True)\n","\n","# split datetime into meaningful features of int types\n","model_df = split_datetime(model_df)\n","\n","# model is not able to handle datetime\n","model_df = model_df.drop(model_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n","\n","# drop na from target\n","model_df.dropna(subset=['target'], inplace=True)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Training & Model Building"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=True, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=9, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=True, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=9, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBRegressor(base_score=None, booster=None, callbacks=None,\n","             colsample_bylevel=None, colsample_bynode=None,\n","             colsample_bytree=None, device=None, early_stopping_rounds=None,\n","             enable_categorical=True, eval_metric=None, feature_types=None,\n","             gamma=None, grow_policy=None, importance_type=None,\n","             interaction_constraints=None, learning_rate=0.3, max_bin=None,\n","             max_cat_threshold=None, max_cat_to_onehot=None,\n","             max_delta_step=None, max_depth=9, max_leaves=None,\n","             min_child_weight=None, missing=nan, monotone_constraints=None,\n","             multi_strategy=None, n_estimators=None, n_jobs=None,\n","             num_parallel_tree=None, random_state=None, ...)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["#X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n","drop_columns = [\n","    'target',\n","    'hours_ahead_forecast_weather',\n","    'row_id',\n","    'data_block_id',\n","    'prediction_unit_id',\n","    'longitude_hist_weather',\n","    'longitude_forecast_weather',\n","    'latitude_hist_weather',\n","    'latitude_forecast_weather'\n","]\n","\n","\n","model = XGBRegressor(enable_categorical=True, max_depth=9, learning_rate=0.3)\n","model.fit(model_df.drop(drop_columns, axis=1), model_df.target)\n","\n","# y_pred = bst.predict(X_test)\n","\n","## main optimisation metric\n","# print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n","# print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Test Data / API"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["\n","def data_prep_data_block(test, client, historical_weather,\n","        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n","\n","    # Datatype conversion\n","    client.date = pd.to_datetime(client.date)\n","\n","    ## Electricity Prices Data\n","    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n","    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n","\n","    ## Forecast Weather Data\n","    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n","    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n","\n","    ## Gas Prices Data\n","    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n","    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n","\n","    ## Historical Weather Data\n","    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n","\n","    ## Train Data & Checking for NULL values\n","    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n","\n","    ## Data Merging (now we merge everything to test)\n","    ### Merge Client\n","    # append '_client' to merged columns\n","    client.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]\n","\n","    # merge train and client\n","    merged_df = pd.merge(test, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n","\n","    ### Merge Gas Prices\n","    # append _gas_prices to columns\n","    gas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]\n","\n","    # merge gas_prices\n","    merged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n","\n","    ### Merge Electricity Prices\n","    # add time column for merging with electricity data\n","    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n","\n","    # Merge electricity prices\n","    # the prices are available hourly -> create new column with time \n","    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n","\n","    # append electricity_prices to column names\n","    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n","\n","    ### Merge Electricity Prices\n","    # merge electricity_prices\n","    merged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n","\n","    ### Merge Historical Weather\n","    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n","\n","    # round lat and long to avoid mismatching due to different accuracy\n","    historical_weather.latitude = historical_weather.latitude.round(1)\n","    historical_weather.longitude = historical_weather.longitude.round(1)\n","\n","    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\n","    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n","\n","    # merge historical weather to get counties\n","    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # get time of day\n","    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n","\n","    # aggregate by county and time (summarize weather stations for same county)\n","    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n","\n","    # append _hist_weather to column names\n","    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n","\n","\n","    # merge to merged_df\n","    merged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')\n","\n","    ### Merge Forecast Weather\n","    # forecast weather\n","\n","    #round lat and long\n","    forecast_weather.latitude = forecast_weather.latitude.round(1)\n","    forecast_weather.longitude = forecast_weather.longitude.round(1)\n","\n","    # merge to get counties\n","    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n","\n","    # # aggregate for duplicate locations\n","    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n","\n","    # append forecast_weather to column names\n","    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n","\n","\n","    # add EET timezone to datetime, and handle daylight-savings\n","    merged_df['datetime_localized'] = merged_df.datetime.dt.tz_localize('EET', ambiguous=True, nonexistent='shift_forward')\n","\n","    # convert UTC timezone to EET timezone in forecast weather\n","    merged_forecast_weather['datetime_EET']  = merged_forecast_weather.forecast_datetime.dt.tz_convert('EET')\n","\n","    # merge forecast_weather\n","    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime_localized', 'county'], right_on=['data_block_id', 'datetime_EET', 'county'], how='left')\n","\n","    # mapping days of the week names and converting to categorical variable\n","    if 'day_of_week' in merged_df.columns:\n","        weekday_map = {\n","            0: 'Monday',\n","            1: 'Tuesday',\n","            2: 'Wednesday',\n","            3: 'Thursday',\n","            4: 'Friday',\n","            5: 'Saturday',\n","            6: 'Sunday'\n","        }\n","        merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n","    # encode categories to category datetype\n","\n","    merged_df['county'] = merged_df['county'].astype('category')\n","    merged_df['product_type'] = merged_df['product_type'].astype('category')\n","    \n","    # model is not able to handle object type\n","    merged_df.drop('time_of_day', axis=1, inplace=True)\n","\n","    # split datetime into meaningful features of int types\n","    merged_df = split_datetime(merged_df)\n","\n","    # model is not able to handle datetime\n","    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n","\n","    return merged_df"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["\n","def data_prep(test, client, historical_weather,\n","        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n","\n","    # Datatype conversion\n","    client.date = pd.to_datetime(client.date)\n","\n","    ## Electricity Prices Data\n","    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n","    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n","\n","    ## Forecast Weather Data\n","    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n","    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n","\n","    ## Gas Prices Data\n","    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n","    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n","\n","    ## Historical Weather Data\n","    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n","\n","    ## Train Data & Checking for NULL values\n","    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n","\n","    ## Data Merging (now we merge everything to test)\n","    ### Merge Client\n","    # append '_client' to merged columns\n","    client.columns = [f\"{column}_client\" if column not in ['county', 'is_business', 'product_type'] else column for column in client.columns]\n","\n","    # merge train and client\n","    merged_df = pd.merge(test, client, on=['county', 'is_business', 'product_type'], how='left')\n","\n","    ### Merge Gas Prices\n","\n","    # merge gas_prices\n","    merged_df[\"lowest_price_per_mwh_gas_prices\"] = gas_prices.lowest_price_per_mwh.min()\n","    merged_df[\"highest_price_per_mwh_gas_prices\"] = gas_prices.highest_price_per_mwh.max()\n","\n","    ### Merge Electricity Prices\n","    # add time column for merging with electricity data\n","    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n","\n","    # Merge electricity prices\n","    # the prices are available hourly -> create new column with time \n","    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n","\n","    # append electricity_prices to column names\n","    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day'] else column for column in electricity_prices.columns]\n","\n","    ### Merge Electricity Prices\n","    # merge electricity_prices\n","    merged_df = pd.merge(merged_df, electricity_prices, on = ['time_of_day'], how='left')\n","\n","    ### Merge Historical Weather\n","    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n","\n","    # round lat and long to avoid mismatching due to different accuracy\n","    historical_weather.latitude = historical_weather.latitude.astype(\"float\").round(1)\n","    historical_weather.longitude = historical_weather.longitude.astype(\"float\").round(1)\n","    \n","    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.astype(\"float\").round(1)\n","    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.astype(\"float\").round(1)\n","\n","    # merge historical weather to get counties\n","    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # get time of day\n","    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n","    \n","    # aggregate by county and time (summarize weather stations for same county)\n","    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime']).mean(numeric_only=True).reset_index()\n","    \n","    # append _hist_weather to column names\n","    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day'] else column for column in merged_hist_weather.columns]\n","\n","    # merge to merged_df\n","    merged_df = pd.merge(merged_df, merged_hist_weather, on=['time_of_day', 'county'], how='left')\n","\n","    ### Merge Forecast Weather\n","    # forecast weather\n","\n","    #round lat and long\n","    forecast_weather.latitude = forecast_weather.latitude.astype(\"float\").round(1)\n","    forecast_weather.longitude = forecast_weather.longitude.astype(\"float\").round(1)\n","\n","    # merge to get counties\n","    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n","\n","    # # aggregate for duplicate locations\n","    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime']).mean(numeric_only=True).reset_index()\n","\n","    # append forecast_weather to column names\n","    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime'] else column for column in merged_forecast_weather.columns]\n","\n","\n","    # merge forecast_weather\n","    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['datetime', 'county'], right_on=['forecast_datetime', 'county'], how='left')\n","    \n","    # split datetime into meaningful features of int types\n","    merged_df = split_datetime(merged_df)\n","    \n","    # mapping days of the week names and converting to categorical variable\n","    if 'day_of_week' in merged_df.columns:\n","        weekday_map = {\n","            0: 'Monday',\n","            1: 'Tuesday',\n","            2: 'Wednesday',\n","            3: 'Thursday',\n","            4: 'Friday',\n","            5: 'Saturday',\n","            6: 'Sunday'\n","        }\n","    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n","    # encode categories to category datetype\n","\n","    merged_df['county'] = merged_df['county'].astype('category')\n","    merged_df['product_type'] = merged_df['product_type'].astype('category')\n","    \n","    # model is not able to handle object type\n","    merged_df.drop('time_of_day', axis=1, inplace=True)\n","\n","    # model is not able to handle datetime\n","    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]', 'object']).columns, axis=1)\n","    \n","    drop_columns = [\n","    'hours_ahead_forecast_weather',\n","    'row_id',\n","    'prediction_unit_id',\n","    'longitude_hist_weather',\n","    'longitude_forecast_weather',\n","    'latitude_hist_weather',\n","    'latitude_forecast_weather',\n","    'currently_scored'\n","    ]\n","    \n","    merged_df.drop(drop_columns, axis=1, inplace=True)\n","\n","    return merged_df"]},{"cell_type":"markdown","metadata":{},"source":["## prepare data frame"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test dataframe #0 \n","    county  is_business  product_type  is_consumption  prediction_datetime  \\\n","0       0            0             1               0  2023-05-28 00:00:00   \n","1       0            0             1               1  2023-05-28 00:00:00   \n","2       0            0             2               0  2023-05-28 00:00:00   \n","\n","    row_id  prediction_unit_id  currently_scored  \n","0  2005872                   0             False  \n","1  2005873                   0             False  \n","2  2005874                   1             False  \n","Revealed targets dataframe #0 \n","    county  is_business  product_type   target  is_consumption  \\\n","0       0            0             1    2.675               0   \n","1       0            0             1  471.887               1   \n","2       0            0             2    0.000               0   \n","\n","              datetime   row_id  prediction_unit_id  \n","0  2023-05-26 00:00:00  1999536                   0  \n","1  2023-05-26 00:00:00  1999537                   0  \n","2  2023-05-26 00:00:00  1999538                   1  \n","Client dataframe #0 \n","    product_type  county  eic_count  installed_capacity  is_business  \\\n","0             1       0        507            4960.215            0   \n","1             2       0         11              34.000            0   \n","2             3       0       1516           15977.560            0   \n","\n","         date  \n","0  2023-05-26  \n","1  2023-05-26  \n","2  2023-05-26  \n","Historical weather dataframe #0 \n","               datetime  temperature  dewpoint  rain  snowfall  \\\n","0  2023-05-26 11:00:00         13.5       9.0   0.0       0.0   \n","1  2023-05-26 11:00:00         13.4       8.9   0.2       0.0   \n","2  2023-05-26 11:00:00         16.4       7.8   0.2       0.0   \n","\n","   surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n","0            1018.5                30              31               3   \n","1            1013.2                47              31              32   \n","2            1017.7                60              21              69   \n","\n","   cloudcover_high  windspeed_10m  winddirection_10m  shortwave_radiation  \\\n","0                0       6.305556                272                592.0   \n","1                0       6.111111                268                612.0   \n","2                0       6.138889                263                655.0   \n","\n","   direct_solar_radiation  diffuse_radiation  latitude  longitude  \n","0                   420.0              172.0      57.6       21.7  \n","1                   446.0              166.0      57.6       22.2  \n","2                   512.0              143.0      57.6       22.7  \n","Forecast weather dataframe #0 \n","    latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n","0      57.6       21.7  2023-05-27 02:00:00            1     9.859155   \n","1      57.6       22.2  2023-05-27 02:00:00            1     5.916284   \n","2      57.6       22.7  2023-05-27 02:00:00            1     9.111963   \n","\n","   dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n","0  5.508813              0.0             0.0        0.026901   \n","1  4.613428              0.0             0.0        0.000000   \n","2  6.878442              0.0             0.0        0.000000   \n","\n","   cloudcover_total  10_metre_u_wind_component  10_metre_v_wind_component  \\\n","0          0.026901                   3.616620                  -1.281012   \n","1          0.000000                   2.164227                  -0.245367   \n","2          0.000000                   3.809247                  -1.583502   \n","\n","     forecast_datetime  direct_solar_radiation  \\\n","0  2023-05-27 03:00:00                     0.0   \n","1  2023-05-27 03:00:00                     0.0   \n","2  2023-05-27 03:00:00                     0.0   \n","\n","   surface_solar_radiation_downwards  snowfall  total_precipitation  \n","0                                0.0       0.0                  0.0  \n","1                                0.0       0.0                  0.0  \n","2                                0.0       0.0                  0.0  \n","Electricity prices dataframe #0 \n","          forecast_date  euros_per_mwh          origin_date\n","0  2023-05-27 00:00:00          87.54  2023-05-26 00:00:00\n","1  2023-05-27 01:00:00          82.69  2023-05-26 01:00:00\n","2  2023-05-27 02:00:00          82.70  2023-05-26 02:00:00\n","Gas prices dataframe #0 \n","   forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date\n","0    2023-05-27                  28.3                   34.1  2023-05-26\n","Sample prediction dataframe #0 \n","     row_id  target\n","0  2005872       0\n","1  2005873       0\n","2  2005874       0\n","Test dataframe #1 \n","    county  is_business  product_type  is_consumption  prediction_datetime  \\\n","0       0            0             1               0  2023-05-29 00:00:00   \n","1       0            0             1               1  2023-05-29 00:00:00   \n","2       0            0             2               0  2023-05-29 00:00:00   \n","\n","    row_id  prediction_unit_id  currently_scored  \n","0  2008992                   0             False  \n","1  2008993                   0             False  \n","2  2008994                   1             False  \n","Revealed targets dataframe #1 \n","    county  is_business  product_type   target  is_consumption  \\\n","0       0            0             1    2.821               0   \n","1       0            0             1  537.429               1   \n","2       0            0             2    0.000               0   \n","\n","              datetime   row_id  prediction_unit_id  \n","0  2023-05-27 00:00:00  2002704                   0  \n","1  2023-05-27 00:00:00  2002705                   0  \n","2  2023-05-27 00:00:00  2002706                   1  \n","Client dataframe #1 \n","    product_type  county  eic_count  installed_capacity  is_business  \\\n","0             1       0        507            4960.215            0   \n","1             2       0         11              35.000            0   \n","2             3       0       1517           15980.560            0   \n","\n","         date  \n","0  2023-05-27  \n","1  2023-05-27  \n","2  2023-05-27  \n","Historical weather dataframe #1 \n","               datetime  temperature  dewpoint  rain  snowfall  \\\n","0  2023-05-27 11:00:00         13.1       6.5   0.0       0.0   \n","1  2023-05-27 11:00:00         12.7       5.7   0.0       0.0   \n","2  2023-05-27 11:00:00         13.0       5.1   0.0       0.0   \n","\n","   surface_pressure  cloudcover_total  cloudcover_low  cloudcover_mid  \\\n","0            1028.1                16               3              14   \n","1            1023.0                20               5              23   \n","2            1027.8                10               3              11   \n","\n","   cloudcover_high  windspeed_10m  winddirection_10m  shortwave_radiation  \\\n","0               15       3.972222                280                594.0   \n","1                7       4.027778                297                583.0   \n","2                4       4.972222                304                595.0   \n","\n","   direct_solar_radiation  diffuse_radiation  latitude  longitude  \n","0                   418.0              176.0      57.6       21.7  \n","1                   398.0              185.0      57.6       22.2  \n","2                   419.0              176.0      57.6       22.7  \n","Forecast weather dataframe #1 \n","    latitude  longitude      origin_datetime  hours_ahead  temperature  \\\n","0      57.6       21.7  2023-05-28 02:00:00            1     9.301904   \n","1      57.6       22.2  2023-05-28 02:00:00            1     6.866357   \n","2      57.6       22.7  2023-05-28 02:00:00            1     9.098047   \n","\n","   dewpoint  cloudcover_high  cloudcover_low  cloudcover_mid  \\\n","0  4.898340              0.0             0.0             0.0   \n","1  3.836816              0.0             0.0             0.0   \n","2  4.527002              0.0             0.0             0.0   \n","\n","   cloudcover_total  10_metre_u_wind_component  10_metre_v_wind_component  \\\n","0               0.0                  -1.028207                   6.487206   \n","1               0.0                  -0.399545                   4.186913   \n","2               0.0                   1.205802                   4.716209   \n","\n","     forecast_datetime  direct_solar_radiation  \\\n","0  2023-05-28 03:00:00                     0.0   \n","1  2023-05-28 03:00:00                     0.0   \n","2  2023-05-28 03:00:00                     0.0   \n","\n","   surface_solar_radiation_downwards  snowfall  total_precipitation  \n","0                                0.0       0.0                  0.0  \n","1                                0.0       0.0                  0.0  \n","2                                0.0       0.0                  0.0  \n","Electricity prices dataframe #1 \n","          forecast_date  euros_per_mwh          origin_date\n","0  2023-05-28 00:00:00          85.00  2023-05-27 00:00:00\n","1  2023-05-28 01:00:00          81.98  2023-05-27 01:00:00\n","2  2023-05-28 02:00:00          79.96  2023-05-27 02:00:00\n","Gas prices dataframe #1 \n","   forecast_date  lowest_price_per_mwh  highest_price_per_mwh origin_date\n","0    2023-05-28                  28.1                   34.1  2023-05-27\n","Sample prediction dataframe #1 \n","     row_id  target\n","0  2008992       0\n","1  2008993       0\n","2  2008994       0\n"]}],"source":["if ON_KAGGLE:\n","    import enefit\n","else:\n","    import sys\n","    sys.path.append('../imports')\n","    import public_timeseries_testing_util as enefit\n","\n","\n","env = enefit.make_env()\n","iter_test = env.iter_test()\n","counter = 0\n","for (test, revealed_targets, client, historical_weather,\n","        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n","    if counter in [0, 1]:\n","        print(f'Test dataframe #{counter} \\n', test.head(3))\n","        print(f'Revealed targets dataframe #{counter} \\n', revealed_targets.head(3))\n","        print(f'Client dataframe #{counter} \\n', client.head(3))\n","        print(f'Historical weather dataframe #{counter} \\n', historical_weather.head(3))\n","        print(f'Forecast weather dataframe #{counter} \\n', forecast_weather.head(3))\n","        print(f'Electricity prices dataframe #{counter} \\n', electricity_prices.head(3))\n","        print(f'Gas prices dataframe #{counter} \\n', gas_prices.head(3))\n","        print(f'Sample prediction dataframe #{counter} \\n', sample_prediction.head(3))\n","    \n","    prepped_df = data_prep(\n","        test, client, historical_weather, forecast_weather, electricity_prices, \n","        gas_prices, sample_prediction, weather_station_to_county_mapping\n","    )\n","    \n","    sample_prediction['target'] = model.predict(prepped_df)\n","    sample_prediction['target'] = sample_prediction['target'].fillna(0).clip(0)\n","\n","\n","    env.predict(sample_prediction)\n","    counter += 1"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7292407,"sourceId":57236,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
