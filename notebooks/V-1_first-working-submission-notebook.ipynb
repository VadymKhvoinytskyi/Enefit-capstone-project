{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# crucial for import API interface and loading data\n","ON_KAGGLE: bool = False"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if not ON_KAGGLE:\n","    import sys\n","    sys.path.append('../imports')\n","    from helper_functions import split_datetime\n","    from actpred_plot import plot_actual_vs_pred\n","    from data_preprocessing import merge_data, remove_col\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import plotly.express as px\n","\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if ON_KAGGLE:\n","    DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\n","else:\n","    DATA_DIR = \"../data/\"\n","\n","# Read CSVs and parse relevant date columns\n","train = pd.read_csv(DATA_DIR + \"train.csv\")\n","client = pd.read_csv(DATA_DIR + \"client.csv\")\n","historical_weather = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\n","forecast_weather = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\n","electricity_prices = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\n","gas_prices = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\n","weather_station_to_county_mapping = pd.read_csv(DATA_DIR + 'weather_station_to_county_mapping.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# We merge all DataFrames \n","merged_df = merge_data(\n","    train, client, historical_weather, forecast_weather, \n","    electricity_prices, gas_prices, weather_station_to_county_mapping\n",")\n","\n","# Drop all non needed columns (ids and timestamps)\n","merged_df = remove_col(merged_df, drop_row_id=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Training & Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["drop_columns = [\n","    'target', 'hours_ahead_forecast_weather',\n","    'row_id', 'data_block_id', 'prediction_unit_id', \n","    'longitude_hist_weather', 'latitude_hist_weather',\n","    'longitude_forecast_weather', 'latitude_forecast_weather'\n","]\n","\n","selected_fields = ['county', 'is_business', 'product_type', 'is_consumption',\n","       'eic_count_client', 'installed_capacity_client',\n","       'rain_hist_weather', 'snowfall_hist_weather',\n","       'cloudcover_total_hist_weather', 'cloudcover_mid_hist_weather',\n","       'cloudcover_high_hist_weather', 'diffuse_radiation_hist_weather',\n","       'temperature_forecast_weather', 'dewpoint_forecast_weather',\n","       'surface_solar_radiation_downwards_forecast_weather',\n","       'total_precipitation_forecast_weather', 'year', 'week', 'hour',\n","       'day_of_year', 'day_of_week'\n","]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n","\n","\n","\n","model = XGBRegressor(enable_categorical=True, max_depth=9, learning_rate=0.3)\n","model.fit(merged_df.drop(['row_id', 'target'], axis=1)[selected_fields], merged_df.target)\n","\n","# y_pred = bst.predict(X_test)\n","\n","## main optimisation metric\n","# print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n","# print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df.sample(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def data_prep(test, client, historical_weather,\n","        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n","\n","    # Datatype conversion\n","    client.date = pd.to_datetime(client.date)\n","\n","    ## Electricity Prices Data\n","    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n","    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n","\n","    ## Forecast Weather Data\n","    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n","    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n","\n","    ## Gas Prices Data\n","    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n","    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n","\n","    ## Historical Weather Data\n","    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n","\n","    ## Train Data & Checking for NULL values\n","    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n","\n","    ## Data Merging (now we merge everything to test)\n","    ### Merge Client\n","    # append '_client' to merged columns\n","    client.columns = [f\"{column}_client\" if column not in ['county', 'is_business', 'product_type'] else column for column in client.columns]\n","\n","    # merge train and client\n","    merged_df = pd.merge(test, client, on=['county', 'is_business', 'product_type'], how='left')\n","\n","    ### Merge Gas Prices\n","\n","    # merge gas_prices\n","    merged_df[\"lowest_price_per_mwh_gas_prices\"] = gas_prices.lowest_price_per_mwh.min()\n","    merged_df[\"highest_price_per_mwh_gas_prices\"] = gas_prices.highest_price_per_mwh.max()\n","\n","    ### Merge Electricity Prices\n","    # add time column for merging with electricity data\n","    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n","\n","    # Merge electricity prices\n","    # the prices are available hourly -> create new column with time \n","    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n","\n","    # append electricity_prices to column names\n","    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day'] else column for column in electricity_prices.columns]\n","\n","    ### Merge Electricity Prices\n","    # merge electricity_prices\n","    merged_df = pd.merge(merged_df, electricity_prices, on = ['time_of_day'], how='left')\n","\n","    ### Merge Historical Weather\n","    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n","\n","    # round lat and long to avoid mismatching due to different accuracy\n","    historical_weather.latitude = historical_weather.latitude.astype(\"float\").round(1)\n","    historical_weather.longitude = historical_weather.longitude.astype(\"float\").round(1)\n","    \n","    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.astype(\"float\").round(1)\n","    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.astype(\"float\").round(1)\n","\n","    # merge historical weather to get counties\n","    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # get time of day\n","    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n","    \n","    # aggregate by county and time (summarize weather stations for same county)\n","    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime']).mean(numeric_only=True).reset_index()\n","    \n","    # append _hist_weather to column names\n","    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day'] else column for column in merged_hist_weather.columns]\n","\n","    # merge to merged_df\n","    merged_df = pd.merge(merged_df, merged_hist_weather, on=['time_of_day', 'county'], how='left')\n","\n","    ### Merge Forecast Weather\n","    # forecast weather\n","\n","    #round lat and long\n","    forecast_weather.latitude = forecast_weather.latitude.astype(\"float\").round(1)\n","    forecast_weather.longitude = forecast_weather.longitude.astype(\"float\").round(1)\n","\n","    # merge to get counties\n","    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n","\n","    # # aggregate for duplicate locations\n","    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime']).mean(numeric_only=True).reset_index()\n","\n","    # append forecast_weather to column names\n","    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime'] else column for column in merged_forecast_weather.columns]\n","\n","\n","    # merge forecast_weather\n","    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['datetime', 'county'], right_on=['forecast_datetime', 'county'], how='left')\n","    \n","    # split datetime into meaningful features of int types\n","    merged_df = split_datetime(merged_df)\n","    \n","    # mapping days of the week names and converting to categorical variable\n","    if 'day_of_week' in merged_df.columns:\n","        weekday_map = {\n","            0: 'Monday',\n","            1: 'Tuesday',\n","            2: 'Wednesday',\n","            3: 'Thursday',\n","            4: 'Friday',\n","            5: 'Saturday',\n","            6: 'Sunday'\n","        }\n","    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n","    # encode categories to category datetype\n","\n","    merged_df['county'] = merged_df['county'].astype('category')\n","    merged_df['product_type'] = merged_df['product_type'].astype('category')\n","    \n","    # model is not able to handle object type\n","    merged_df.drop('time_of_day', axis=1, inplace=True)\n","\n","    # model is not able to handle datetime\n","    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]', 'object']).columns, axis=1)\n","    \n","    drop_columns = [\n","    'hours_ahead_forecast_weather',\n","    'row_id',\n","    'prediction_unit_id',\n","    'longitude_hist_weather',\n","    'longitude_forecast_weather',\n","    'latitude_hist_weather',\n","    'latitude_forecast_weather',\n","    'currently_scored'\n","    ]\n","    \n","    merged_df.drop(drop_columns, axis=1, inplace=True)\n","\n","    return merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def data_prep_with_row_id(test, client, historical_weather,\n","        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n","\n","    # Datatype conversion\n","    client.date = pd.to_datetime(client.date)\n","\n","    ## Electricity Prices Data\n","    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n","    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n","\n","    ## Forecast Weather Data\n","    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n","    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n","\n","    ## Gas Prices Data\n","    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n","    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n","\n","    ## Historical Weather Data\n","    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n","\n","    ## Train Data & Checking for NULL values\n","    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n","\n","    ## Data Merging (now we merge everything to test)\n","    ### Merge Client\n","    # append '_client' to merged columns\n","    client.columns = [f\"{column}_client\" if column not in ['county', 'is_business', 'product_type'] else column for column in client.columns]\n","\n","    # merge train and client\n","    merged_df = pd.merge(test, client, on=['county', 'is_business', 'product_type'], how='left')\n","\n","    ### Merge Gas Prices\n","\n","    # merge gas_prices\n","    merged_df[\"lowest_price_per_mwh_gas_prices\"] = gas_prices.lowest_price_per_mwh.min()\n","    merged_df[\"highest_price_per_mwh_gas_prices\"] = gas_prices.highest_price_per_mwh.max()\n","\n","    ### Merge Electricity Prices\n","    # add time column for merging with electricity data\n","    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n","\n","    # Merge electricity prices\n","    # the prices are available hourly -> create new column with time \n","    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n","\n","    # append electricity_prices to column names\n","    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day'] else column for column in electricity_prices.columns]\n","\n","    ### Merge Electricity Prices\n","    # merge electricity_prices\n","    merged_df = pd.merge(merged_df, electricity_prices, on = ['time_of_day'], how='left')\n","\n","    ### Merge Historical Weather\n","    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n","\n","    # round lat and long to avoid mismatching due to different accuracy\n","    historical_weather.latitude = historical_weather.latitude.astype(\"float\").round(1)\n","    historical_weather.longitude = historical_weather.longitude.astype(\"float\").round(1)\n","    \n","    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.astype(\"float\").round(1)\n","    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.astype(\"float\").round(1)\n","\n","    # merge historical weather to get counties\n","    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # get time of day\n","    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n","    \n","    # aggregate by county and time (summarize weather stations for same county)\n","    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime']).mean(numeric_only=True).reset_index()\n","    \n","    # append _hist_weather to column names\n","    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day'] else column for column in merged_hist_weather.columns]\n","\n","    # merge to merged_df\n","    merged_df = pd.merge(merged_df, merged_hist_weather, on=['time_of_day', 'county'], how='left')\n","\n","    ### Merge Forecast Weather\n","    # forecast weather\n","\n","    #round lat and long\n","    forecast_weather.latitude = forecast_weather.latitude.astype(\"float\").round(1)\n","    forecast_weather.longitude = forecast_weather.longitude.astype(\"float\").round(1)\n","\n","    # merge to get counties\n","    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n","    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n","\n","    # # aggregate for duplicate locations\n","    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime']).mean(numeric_only=True).reset_index()\n","\n","    # append forecast_weather to column names\n","    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime'] else column for column in merged_forecast_weather.columns]\n","\n","\n","    # merge forecast_weather\n","    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['datetime', 'county'], right_on=['forecast_datetime', 'county'], how='left')\n","    \n","    # split datetime into meaningful features of int types\n","    merged_df = split_datetime(merged_df)\n","    \n","    # mapping days of the week names and converting to categorical variable\n","    if 'day_of_week' in merged_df.columns:\n","        weekday_map = {\n","            0: 'Monday',\n","            1: 'Tuesday',\n","            2: 'Wednesday',\n","            3: 'Thursday',\n","            4: 'Friday',\n","            5: 'Saturday',\n","            6: 'Sunday'\n","        }\n","        merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n","    merged_df['day_of_week'] = merged_df['day_of_week'].astype('category')\n","    # encode categories to category datetype\n","\n","    merged_df['county'] = merged_df['county'].astype('category')\n","    merged_df['product_type'] = merged_df['product_type'].astype('category')\n","    \n","    # model is not able to handle object type\n","    merged_df.drop('time_of_day', axis=1, inplace=True)\n","\n","    # model is not able to handle datetime\n","    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]', 'object']).columns, axis=1)\n","    \n","    drop_columns = [\n","        'hours_ahead_forecast_weather',\n","        'prediction_unit_id',\n","        'longitude_hist_weather',\n","        'longitude_forecast_weather',\n","        'latitude_hist_weather',\n","        'latitude_forecast_weather',\n","        'currently_scored'\n","    ]\n","    \n","    merged_df.drop(drop_columns, axis=1, inplace=True)\n","\n","    return merged_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if ON_KAGGLE:\n","    import enefit\n","else:\n","    import sys\n","    sys.path.append('../imports')\n","    import public_timeseries_testing_util as enefit\n","\n","\n","# copy of df before new data\n","merged_df['row_id'] = merged_df['row_id'].astype('int', errors='ignore')\n","\n","env = enefit.make_env()\n","iter_test = env.iter_test()\n","\n","counter = 0\n","previous_revealed_targets = pd.DataFrame()\n","\n","# necessary because of row_id overlap in old and new data\n","if not ON_KAGGLE:\n","    merged_df = merged_df[merged_df['row_id'] < 2005872]\n","\n","print('Merged_df before loop \\n', merged_df)\n","\n","for (test, revealed_targets, client, historical_weather,\n","    forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n"," \n","    # logs\n","    print('Counter:', counter)\n","    look_index = 2005872\n","    try:\n","        print(f'Merged_df index {look_index} \\n', merged_df[merged_df['row_id'] == 2005872])\n","    except:\n","        print(f'{look_index} is not there yet')\n","\n","    # merged_df['day_of_week'] = merged_df['day_of_week'].astype('category')\n","\n","    try: \n","        # drop columns if target is na\n","        # model_df = merged_df.dropna(subset=['target'])\n","        model_df = merged_df.copy()\n","    except:\n","        print('some na targets were dropped')\n","        # create alias anyway\n","        model_df = merged_df.copy()\n","\n","    # model.fit(model_df.drop(drop_columns, axis=1)[selected_fields], model_df.target)\n","\n","    \n","    if counter in [0, 1]:\n","        pass\n","        # print(f'Test dataframe #{counter} \\n', test.head(3))\n","        # print(f'Revealed targets dataframe #{counter} \\n', revealed_targets.head(3))\n","        # print(f'Client dataframe #{counter} \\n', client.head(3))\n","        # print(f'Historical weather dataframe #{counter} \\n', historical_weather.head(3))\n","        # print(f'Forecast weather dataframe #{counter} \\n', forecast_weather.head(3))\n","        # print(f'Electricity prices dataframe #{counter} \\n', electricity_prices.head(3))\n","        # print(f'Gas prices dataframe #{counter} \\n', gas_prices.head(3))\n","        # print(f'Sample prediction dataframe #{counter} \\n', sample_prediction.head(3))\n","    \n","    prepped_df = merge_data(\n","        test, client, historical_weather, forecast_weather, \n","        electricity_prices, gas_prices, weather_station_to_county_mapping\n","    )\n","    print('Prepped_df \\n', prepped_df)\n","\n","    prepped_df = remove_col(prepped_df, drop_row_id=False)\n","\n","    # print(merged_df.columns, '\\n', prepped_df.columns)\n","\n","    # bring new data to storage\n","    merged_df = pd.concat([merged_df, prepped_df], axis=0, ignore_index=True)\n","    \n","    try:\n","        # add revealed targets to data\n","        revealed_targets = pd.concat([previous_revealed_targets, revealed_targets], axis=0, ignore_index=True)\n","\n","        # imputing targets\n","        targets_indexes = merged_df['row_id'].loc[revealed_targets['row_id']].index\n","        # targets_indexes = for  in merged_df['row_id']\n","        print('Targets indexes \\n', targets_indexes)\n","        merged_df['target'].iloc[targets_indexes] = revealed_targets['target']\n","        # merged_df[['row_id', 'target']] = merged_df[['row_id', 'target']].apply(lambda x: if x.to_list() in revealed_targets['row_id'])\n","\n","        # reset variable\n","        previous_revealed_targets = pd.DataFrame()\n","    except KeyError as e:\n","        # store unused revealed targets for the next try\n","        print('KeyError occurred')\n","        print(e)\n","        previous_revealed_targets = revealed_targets.copy()\n","        \n","    # make and put prediction\n","    sample_prediction['target'] = model.predict(prepped_df.drop('row_id', axis=1)[selected_fields])\n","    sample_prediction['target'] = sample_prediction['target'].fillna(0).clip(0)\n","\n","    env.predict(sample_prediction)\n","    counter += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["merged_df[merged_df['row_id'] == 2005872]\n","# merged_df.iloc[2005872]"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":7292407,"sourceId":57236,"sourceType":"competition"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.3"}},"nbformat":4,"nbformat_minor":4}
