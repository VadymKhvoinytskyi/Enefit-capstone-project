{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime(data, col=\"datetime\"):\n",
    "    # What columns are of type datetime?\n",
    "    datetime_columns = data.select_dtypes(include='datetime64').columns\n",
    "    \n",
    "    for c in datetime_columns:\n",
    "        print(f\"Timezone for {c} is {data[c].dt.tz}\")\n",
    "\n",
    "    # Adding columns for date & time\n",
    "    data['year']    = data[col].dt.year\n",
    "    # data['quarter'] = data[col].dt.quarter\n",
    "    data['month']   = data[col].dt.month\n",
    "    data['week']    = data[col].dt.isocalendar().week\n",
    "    data['hour']    = data[col].dt.hour \n",
    "\n",
    "    data['day_of_year']  = data[col].dt.day_of_year\n",
    "    data['day_of_month'] = data[col].dt.day\n",
    "    data['day_of_week']  = data[col].dt.day_of_week\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge test data to other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "## Client Data\n",
    "client = pd.read_csv('../data/example_test_files/client.csv')\n",
    "\n",
    "# Datatype conversion\n",
    "client.date = pd.to_datetime(client.date)\n",
    "\n",
    "## Electricity Prices Data\n",
    "electricity_prices = pd.read_csv('../data/example_test_files/electricity_prices.csv')\n",
    "electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n",
    "electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n",
    "\n",
    "## Forecast Weather Data\n",
    "forecast_weather = pd.read_csv('../data/example_test_files/forecast_weather.csv')\n",
    "forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n",
    "forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n",
    "\n",
    "## Gas Prices Data\n",
    "gas_prices = pd.read_csv('../data/example_test_files/gas_prices.csv')\n",
    "gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n",
    "gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n",
    "\n",
    "## Historical Weather Data\n",
    "historical_weather = pd.read_csv('../data/example_test_files/historical_weather.csv')\n",
    "historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n",
    "\n",
    "## Train Data & Checking for NULL values\n",
    "test = pd.read_csv('../data/example_test_files/test.csv')\n",
    "test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "weather_station_to_county_mapping = pd.read_csv('../data/weather_station_to_county_mapping.csv')\n",
    "\n",
    "\n",
    "\n",
    "## Data Merging (now we merge everything to test)\n",
    "### Merge Client\n",
    "# append '_client' to merged columns\n",
    "client.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]\n",
    "# merge train and client\n",
    "\n",
    "merged_df = pd.merge(test, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n",
    "\n",
    "\n",
    "### Merge Gas Prices\n",
    "# append _gas_prices to columns\n",
    "gas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]\n",
    "\n",
    "# merge gas_prices\n",
    "merged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "### Merge Electricity Prices\n",
    "# add time column for merging with electricity data\n",
    "merged_df['time_of_day'] = merged_df['datetime'].dt.time\n",
    "\n",
    "# Merge electricity prices\n",
    "# the prices are available hourly -> create new column with time \n",
    "electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n",
    "\n",
    "\n",
    "# append electricity_prices to column names\n",
    "electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n",
    "\n",
    "\n",
    "### Merge Electricity Prices\n",
    "# merge electricity_prices\n",
    "merged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n",
    "\n",
    "### Merge Historical Weather\n",
    "# get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n",
    "\n",
    "# round lat and long to avoid mismatching due to different accuracy\n",
    "historical_weather.latitude = historical_weather.latitude.round(1)\n",
    "historical_weather.longitude = historical_weather.longitude.round(1)\n",
    "\n",
    "weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\n",
    "weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n",
    "\n",
    "# merge historical weather to get counties\n",
    "merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n",
    "# get time of day\n",
    "merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n",
    "\n",
    "# aggregate by county and time (summarize weather stations for same county)\n",
    "merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# append _hist_weather to column names\n",
    "merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n",
    "\n",
    "\n",
    "# merge to merged_df\n",
    "merged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')\n",
    "\n",
    "### Merge Forecast Weather\n",
    "# forecast weather\n",
    "\n",
    "#round lat and long\n",
    "forecast_weather.latitude = forecast_weather.latitude.round(1)\n",
    "forecast_weather.longitude = forecast_weather.longitude.round(1)\n",
    "\n",
    "# merge to get counties\n",
    "merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n",
    "# merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n",
    "\n",
    "# # aggregate for duplicate locations\n",
    "merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# append forecast_weather to column names\n",
    "merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n",
    "\n",
    "\n",
    "# add EET timezone to datetime, and handle daylight-savings\n",
    "merged_df['datetime_localized'] = merged_df.datetime.dt.tz_localize('EET', ambiguous=True, nonexistent='shift_forward')\n",
    "\n",
    "# convert UTC timezone to EET timezone in forecast weather\n",
    "merged_forecast_weather['datetime_EET']  = merged_forecast_weather.forecast_datetime.dt.tz_convert('EET')\n",
    "\n",
    "# merge forecast_weather\n",
    "merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime_localized', 'county'], right_on=['data_block_id', 'datetime_EET', 'county'], how='left')\n",
    "\n",
    "\n",
    "merged_df.to_parquet('../data/example_test_files/merged_test_df.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping days of the week names and converting to categorical variable\n",
    "if 'day_of_week' in merged_df.columns:\n",
    "    weekday_map = {\n",
    "        0: 'Monday',\n",
    "        1: 'Tuesday',\n",
    "        2: 'Wednesday',\n",
    "        3: 'Thursday',\n",
    "        4: 'Friday',\n",
    "        5: 'Saturday',\n",
    "        6: 'Sunday'\n",
    "    }\n",
    "    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categories to category datetype\n",
    "\n",
    "merged_df['county'] = merged_df['county'].astype('category')\n",
    "merged_df['product_type'] = merged_df['product_type'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df for modelling\n",
    "model_df = merged_df\n",
    "\n",
    "# model is not able to handle object type\n",
    "model_df.drop('time_of_day', axis=1, inplace=True)\n",
    "\n",
    "# split datetime into meaningful features of int types\n",
    "model_df = split_datetime(model_df)\n",
    "\n",
    "# model is not able to handle datetime\n",
    "model_df = model_df.drop(model_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n",
    "\n",
    "## drop na from target\n",
    "#model_df.dropna(subset=['target'], inplace=True)  # we dont have target in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from grid search on train data\n",
    "\n",
    "with open('../models/XGBoost_first_best_model.pickle', 'rb') as file:\n",
    "    model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test data\n",
    "\n",
    "model_df['target_pred'] = model.predict(model_df.drop(['prediction_datetime', 'currently_scored'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation: load revealed_targets\n",
    "\n",
    "revealed_targets = pd.read_csv('../data/example_test_files/revealed_targets.csv')\n",
    "revealed_targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge revealed_targets to model_df\n",
    "\n",
    "model_df = model_df.merge(revealed_targets[['target', 'row_id']], on='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "\n",
    "mae = mean_absolute_error(model_df.target, model_df.target_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "\n",
    "# we saw that sometimes negative production is predicted -> correct that\n",
    "\n",
    "model_df['target_corrected'] = model_df['target_pred'].apply(lambda x: x if x>0 else 0)\n",
    "\n",
    "mae = mean_absolute_error(model_df.target, model_df.target_corrected)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try working with the Enefit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../data')\n",
    "\n",
    "import public_timeseries_testing_util as enefit\n",
    "\n",
    "\n",
    "env = enefit.make_env()\n",
    "iter_test = env.iter_test()\n",
    "counter = 0\n",
    "for (test, revealed_targets, client, historical_weather,\n",
    "        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n",
    "    if counter == 0:\n",
    "        print(test.head(3))\n",
    "        print(revealed_targets.head(3))\n",
    "        print(client.head(3))\n",
    "        print(historical_weather.head(3))\n",
    "        print(forecast_weather.head(3))\n",
    "        print(electricity_prices.head(3))\n",
    "        print(gas_prices.head(3))\n",
    "        print(sample_prediction.head(3))\n",
    "    sample_prediction['target'] = 0\n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "\n",
    "    ## continue from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
