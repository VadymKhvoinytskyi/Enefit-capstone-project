{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization - Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Add the '../imports' directory to the sys.path list\n",
    "import sys\n",
    "sys.path.append('../imports')\n",
    "from helper_functions import split_datetime\n",
    "from data_preprocessing import merge_data, remove_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train data\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "\n",
    "# Read CSVs and parse relevant date columns\n",
    "train = pd.read_csv(DATA_DIR + \"train.csv\")\n",
    "client_train = pd.read_csv(DATA_DIR + \"client.csv\")\n",
    "historical_weather_train = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\n",
    "forecast_weather_train = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\n",
    "electricity_prices_train = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\n",
    "gas_prices_train = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\n",
    "weather_station_to_county_mapping = pd.read_csv(DATA_DIR + 'weather_station_to_county_mapping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We merge all DataFrames \n",
    "merged_train_df = merge_data(train, client_train, historical_weather_train,\n",
    "        forecast_weather_train, electricity_prices_train, gas_prices_train, weather_station_to_county_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all non needed columns (ids and timestamps)\n",
    "model_df = remove_col(merged_train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "       False, False,  True,  True, False,  True, False,  True,  True,\n",
       "       False, False, False, False,  True,  True,  True, False, False,\n",
       "       False, False, False, False, False,  True, False,  True,  True,\n",
       "       False,  True,  True,  True, False,  True])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_sel_df = model_df.copy()\n",
    "\n",
    "# train-test split\n",
    "X = feat_sel_df.drop('target', axis=1)\n",
    "y = feat_sel_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "## feature selection\n",
    "xgboost =  XGBRegressor(enable_categorical = True)\n",
    "sfs = SequentialFeatureSelector(xgboost, scoring='neg_mean_absolute_error')\n",
    "sfs.fit(X_train, y_train)\n",
    "\n",
    "sfs.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['county', 'is_business', 'product_type', 'is_consumption',\n",
       "       'eic_count_client', 'installed_capacity_client',\n",
       "       'lowest_price_per_mwh_gas_prices',\n",
       "       'highest_price_per_mwh_gas_prices',\n",
       "       'euros_per_mwh_electricity_prices', 'temperature_hist_weather',\n",
       "       'dewpoint_hist_weather', 'rain_hist_weather',\n",
       "       'snowfall_hist_weather', 'surface_pressure_hist_weather',\n",
       "       'cloudcover_total_hist_weather', 'cloudcover_low_hist_weather',\n",
       "       'cloudcover_mid_hist_weather', 'cloudcover_high_hist_weather',\n",
       "       'windspeed_10m_hist_weather', 'winddirection_10m_hist_weather',\n",
       "       'shortwave_radiation_hist_weather',\n",
       "       'direct_solar_radiation_hist_weather',\n",
       "       'diffuse_radiation_hist_weather', 'temperature_forecast_weather',\n",
       "       'dewpoint_forecast_weather', 'cloudcover_high_forecast_weather',\n",
       "       'cloudcover_low_forecast_weather',\n",
       "       'cloudcover_mid_forecast_weather',\n",
       "       'cloudcover_total_forecast_weather',\n",
       "       '10_metre_u_wind_component_forecast_weather',\n",
       "       '10_metre_v_wind_component_forecast_weather',\n",
       "       'direct_solar_radiation_forecast_weather',\n",
       "       'surface_solar_radiation_downwards_forecast_weather',\n",
       "       'snowfall_forecast_weather',\n",
       "       'total_precipitation_forecast_weather', 'year', 'month', 'week',\n",
       "       'hour', 'day_of_year', 'day_of_month', 'day_of_week'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sfs.feature_names_in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['county', 'is_business', 'product_type', 'is_consumption',\n",
       "       'eic_count_client', 'installed_capacity_client',\n",
       "       'rain_hist_weather', 'snowfall_hist_weather',\n",
       "       'cloudcover_total_hist_weather', 'cloudcover_mid_hist_weather',\n",
       "       'cloudcover_high_hist_weather', 'diffuse_radiation_hist_weather',\n",
       "       'temperature_forecast_weather', 'dewpoint_forecast_weather',\n",
       "       'surface_solar_radiation_downwards_forecast_weather',\n",
       "       'total_precipitation_forecast_weather', 'year', 'week', 'hour',\n",
       "       'day_of_year', 'day_of_week'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sfs.feature_names_in_[sfs.get_support()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected features:\n",
    "\n",
    "['county', 'is_business', 'product_type', 'is_consumption',\n",
    "       'eic_count_client', 'installed_capacity_client',\n",
    "       'rain_hist_weather', 'snowfall_hist_weather',\n",
    "       'cloudcover_total_hist_weather', 'cloudcover_mid_hist_weather',\n",
    "       'cloudcover_high_hist_weather', 'diffuse_radiation_hist_weather',\n",
    "       'temperature_forecast_weather', 'dewpoint_forecast_weather',\n",
    "       'surface_solar_radiation_downwards_forecast_weather',\n",
    "       'total_precipitation_forecast_weather', 'year', 'week', 'hour',\n",
    "       'day_of_year', 'day_of_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>is_business</th>\n",
       "      <th>product_type</th>\n",
       "      <th>is_consumption</th>\n",
       "      <th>eic_count_client</th>\n",
       "      <th>installed_capacity_client</th>\n",
       "      <th>rain_hist_weather</th>\n",
       "      <th>snowfall_hist_weather</th>\n",
       "      <th>cloudcover_total_hist_weather</th>\n",
       "      <th>cloudcover_mid_hist_weather</th>\n",
       "      <th>...</th>\n",
       "      <th>diffuse_radiation_hist_weather</th>\n",
       "      <th>temperature_forecast_weather</th>\n",
       "      <th>dewpoint_forecast_weather</th>\n",
       "      <th>surface_solar_radiation_downwards_forecast_weather</th>\n",
       "      <th>total_precipitation_forecast_weather</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018347</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>6.748584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018348</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>624.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>6.748584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018349</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>624.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>6.748584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018350</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2188.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>6.748584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018351</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2188.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>16.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.484033</td>\n",
       "      <td>6.748584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017824 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        county  is_business product_type  is_consumption  eic_count_client  \\\n",
       "0            0            0            1               0               NaN   \n",
       "1            0            0            1               1               NaN   \n",
       "2            0            0            2               0               NaN   \n",
       "3            0            0            2               1               NaN   \n",
       "4            0            0            3               0               NaN   \n",
       "...        ...          ...          ...             ...               ...   \n",
       "2018347     15            1            0               1              15.0   \n",
       "2018348     15            1            1               0              20.0   \n",
       "2018349     15            1            1               1              20.0   \n",
       "2018350     15            1            3               0              55.0   \n",
       "2018351     15            1            3               1              55.0   \n",
       "\n",
       "         installed_capacity_client  rain_hist_weather  snowfall_hist_weather  \\\n",
       "0                              NaN                NaN                    NaN   \n",
       "1                              NaN                NaN                    NaN   \n",
       "2                              NaN                NaN                    NaN   \n",
       "3                              NaN                NaN                    NaN   \n",
       "4                              NaN                NaN                    NaN   \n",
       "...                            ...                ...                    ...   \n",
       "2018347                      620.0                0.0                    0.0   \n",
       "2018348                      624.5                0.0                    0.0   \n",
       "2018349                      624.5                0.0                    0.0   \n",
       "2018350                     2188.2                0.0                    0.0   \n",
       "2018351                     2188.2                0.0                    0.0   \n",
       "\n",
       "         cloudcover_total_hist_weather  cloudcover_mid_hist_weather  ...  \\\n",
       "0                                  NaN                          NaN  ...   \n",
       "1                                  NaN                          NaN  ...   \n",
       "2                                  NaN                          NaN  ...   \n",
       "3                                  NaN                          NaN  ...   \n",
       "4                                  NaN                          NaN  ...   \n",
       "...                                ...                          ...  ...   \n",
       "2018347                           21.2                         16.4  ...   \n",
       "2018348                           21.2                         16.4  ...   \n",
       "2018349                           21.2                         16.4  ...   \n",
       "2018350                           21.2                         16.4  ...   \n",
       "2018351                           21.2                         16.4  ...   \n",
       "\n",
       "         diffuse_radiation_hist_weather  temperature_forecast_weather  \\\n",
       "0                                   NaN                           NaN   \n",
       "1                                   NaN                           NaN   \n",
       "2                                   NaN                           NaN   \n",
       "3                                   NaN                           NaN   \n",
       "4                                   NaN                           NaN   \n",
       "...                                 ...                           ...   \n",
       "2018347                             0.0                     11.484033   \n",
       "2018348                             0.0                     11.484033   \n",
       "2018349                             0.0                     11.484033   \n",
       "2018350                             0.0                     11.484033   \n",
       "2018351                             0.0                     11.484033   \n",
       "\n",
       "         dewpoint_forecast_weather  \\\n",
       "0                              NaN   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3                              NaN   \n",
       "4                              NaN   \n",
       "...                            ...   \n",
       "2018347                   6.748584   \n",
       "2018348                   6.748584   \n",
       "2018349                   6.748584   \n",
       "2018350                   6.748584   \n",
       "2018351                   6.748584   \n",
       "\n",
       "         surface_solar_radiation_downwards_forecast_weather  \\\n",
       "0                                                      NaN    \n",
       "1                                                      NaN    \n",
       "2                                                      NaN    \n",
       "3                                                      NaN    \n",
       "4                                                      NaN    \n",
       "...                                                    ...    \n",
       "2018347                                                0.0    \n",
       "2018348                                                0.0    \n",
       "2018349                                                0.0    \n",
       "2018350                                                0.0    \n",
       "2018351                                                0.0    \n",
       "\n",
       "         total_precipitation_forecast_weather  year  week  hour  day_of_year  \\\n",
       "0                                         NaN  2021    35     0          244   \n",
       "1                                         NaN  2021    35     0          244   \n",
       "2                                         NaN  2021    35     0          244   \n",
       "3                                         NaN  2021    35     0          244   \n",
       "4                                         NaN  2021    35     0          244   \n",
       "...                                       ...   ...   ...   ...          ...   \n",
       "2018347                                   0.0  2023    22    23          151   \n",
       "2018348                                   0.0  2023    22    23          151   \n",
       "2018349                                   0.0  2023    22    23          151   \n",
       "2018350                                   0.0  2023    22    23          151   \n",
       "2018351                                   0.0  2023    22    23          151   \n",
       "\n",
       "         day_of_week  \n",
       "0                  2  \n",
       "1                  2  \n",
       "2                  2  \n",
       "3                  2  \n",
       "4                  2  \n",
       "...              ...  \n",
       "2018347            2  \n",
       "2018348            2  \n",
       "2018349            2  \n",
       "2018350            2  \n",
       "2018351            2  \n",
       "\n",
       "[2017824 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = sfs.feature_names_in_[sfs.get_support()].tolist()\n",
    "\n",
    "\n",
    "model_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error test 49.646839153001004\n",
      "Mean absolute error train 48.56717060826106\n"
     ]
    }
   ],
   "source": [
    "#run model again, with selected features\n",
    "\n",
    "\n",
    "df = model_df.copy()\n",
    "## do stuff to model_df\n",
    "\n",
    "# only keep columns selected by SFS\n",
    "cols = sfs.feature_names_in_[sfs.get_support()].tolist()\n",
    "df = df[cols]\n",
    "\n",
    "# train-test split\n",
    "X = df\n",
    "y = model_df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# training\n",
    "model = XGBRegressor(enable_categorical=True) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluation\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_test_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Parameters\n",
    "\n",
    "What parameters can we tune?\n",
    "Source: https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "- `booster` [default: `gbtree`]: \n",
    "  - Description: Specifies the booster type to use.\n",
    "  - Options: \n",
    "    - `gbtree`: Uses tree-based models.\n",
    "    - `dart`: Similar to `gbtree`, but with dropout.\n",
    "    - `gblinear`: Uses linear functions.\n",
    "    \n",
    "- `eta` [default: `0.3`, alias: `learning_rate`]: \n",
    "  - Description: Step size shrinkage used in update to prevent overfitting. \n",
    "  - Range: `[0, 1]`\n",
    "\n",
    "- `max_depth` [default: `6`]: \n",
    "  - Description: Maximum depth of a tree. Increasing this value will make the model more complex and likely to overfit. \n",
    "  - Range: `[0, ∞]` (0 indicates no limit)\n",
    "\n",
    "- `subsample` [default: `1`]: \n",
    "  - Description: Subsample ratio of the training instances to prevent overfitting. \n",
    "  - Range: `(0, 1]`\n",
    "\n",
    "- `lambda` [default: `1`, alias: `reg_lambda`]: \n",
    "  - Description: L2 regularization term on weights. \n",
    "  - Range: `[0, ∞]`\n",
    "\n",
    "- `alpha` [default: `0`, alias: `reg_alpha`]: \n",
    "  - Description: L1 regularization term on weights. \n",
    "  - Range: `[0, ∞]`\n",
    "\n",
    "- `eval_metric` [default: according to objective]: \n",
    "  - Description: Evaluation metrics for validation data. \n",
    "  - Note: A default metric is assigned according to the objective (e.g., `rmse` for regression, `logloss` for classification). Users can add multiple evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "\n",
    "First only searching different tree level depths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with gridsearch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "# Define a range of hyperparameters to tune\n",
    "param_grid = {\n",
    "    'max_depth': [6, 7, 8, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5],\n",
    "    #'n_estimators': [100, 200, 300, 500],\n",
    "    #'subsample': [0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor with enable_categorical=True\n",
    "xgb_reg = XGBRegressor(enable_categorical=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output of grid search (best model) as pickle, so we can call it for the test data in modelling_test_data.ipynb\n",
    "with open('../models/XGBoost_first_best_model.pickle', 'wb') as file:\n",
    "    pickle.dump(best_model,  file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We should run the grid search again, but with the reduced number of columns\n",
    "(don't forget)\n",
    "- reduce overfitting? (how?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking best model's MAE on test set\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking best model's MAE on train set\n",
    "\n",
    "y_pred = best_model.predict(X_train)\n",
    "\n",
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearch\n",
    "Different parameters are tuned, and df is split into consumption/production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search, but splitting the df into consumption/production, and choosing different parameters for tuning\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "drop_columns = [\n",
    "    'target',\n",
    "    'hours_ahead_forecast_weather',\n",
    "    'row_id',\n",
    "    'data_block_id',\n",
    "    'prediction_unit_id',\n",
    "    'longitude_hist_weather',\n",
    "    'longitude_forecast_weather',\n",
    "    'latitude_hist_weather',\n",
    "    'latitude_forecast_weather'\n",
    "]\n",
    "# max_depth 15 leads to overfitting\n",
    "params = {\n",
    "    'gamma': [0, 0.1, 1, 10],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_child_weight': [0, 1, 4, 8],\n",
    "    'lambda': [0, 0.01, 0.1, 1],\n",
    "    'num_parallel_tree': [1, 2, 3],\n",
    "}\n",
    "# consumption model\n",
    "X_train, X_test, y_train_cons,  y_test_cons = train_test_split(\n",
    "    model_df.drop(drop_columns, axis=1).query('is_consumption == 1'),\n",
    "    model_df.query('is_consumption == 1')['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "bst_cons = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(enable_categorical=True),\n",
    "    param_distributions=params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=10,\n",
    "    cv=2\n",
    ")\n",
    "bst_cons.fit(X_train, y_train_cons)\n",
    "y_pred_test_cons = bst_cons.predict(X_test)\n",
    "y_pred_train_cons = bst_cons.predict(X_train)\n",
    "print('Mean absolute error train consumption', mean_absolute_error(y_train_cons, y_pred_train_cons))\n",
    "print('Mean absolute error test consumption', mean_absolute_error(y_test_cons, y_pred_test_cons))\n",
    "# production model\n",
    "X_train, X_test, y_train_prod,  y_test_prod = train_test_split(\n",
    "    model_df.drop(drop_columns, axis=1).query('is_consumption == 0'),\n",
    "    model_df.query('is_consumption == 0')['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "bst_prod = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(enable_categorical=True),\n",
    "    param_distributions=params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=10,\n",
    "    cv=2\n",
    ")\n",
    "bst_prod.fit(X_train, y_train_prod)\n",
    "y_pred_test_prod = bst_prod.predict(X_test)\n",
    "y_pred_train_prod = bst_prod.predict(X_train)\n",
    "print('Mean absolute error train production', mean_absolute_error(y_train_prod, y_pred_train_prod))\n",
    "print('Mean absolute error test production', mean_absolute_error(y_test_prod, y_pred_test_prod))\n",
    "# overall score\n",
    "print(\n",
    "    'Mean absolute error train overall',\n",
    "    mean_absolute_error(\n",
    "          pd.concat([pd.Series(y_train_cons), pd.Series(y_train_prod)]),\n",
    "          pd.concat([pd.Series(y_pred_train_cons), pd.Series(y_pred_train_prod)])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    'Mean absolute error test overall',\n",
    "    mean_absolute_error(\n",
    "        pd.concat([pd.Series(y_test_cons), pd.Series(y_test_prod)]),\n",
    "        pd.concat([pd.Series(y_pred_test_cons), pd.Series(y_pred_test_prod)])\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is quite similar with the two hyperparameter search, max tree depth level is probably somewhere between 8 and 10.\n",
    "We need to validate our model on the test dataset, to see its reliability."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
