{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"}],"dockerImageVersionId":30626,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Submission Notebook\n## Preparing and Merging Train Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\n\n# Read CSVs and parse relevant date columns\ntrain = pd.read_csv(DATA_DIR + \"train.csv\")\nclient = pd.read_csv(DATA_DIR + \"client.csv\")\nhistorical_weather = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\nforecast_weather = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\nelectricity_prices = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\ngas_prices = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\nweather_station_to_county_mapping = pd.read_csv(DATA_DIR + 'weather_station_to_county_mapping.csv')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Client Data","metadata":{}},{"cell_type":"code","source":"# Datatype conversion\nclient.date = pd.to_datetime(client.date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Electricity Prices Data","metadata":{}},{"cell_type":"code","source":"electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\nelectricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Forecast Weather Data","metadata":{}},{"cell_type":"code","source":"forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\nforecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Gas Prices Data","metadata":{}},{"cell_type":"code","source":"gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\ngas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Historical Weather Data","metadata":{}},{"cell_type":"code","source":"historical_weather.datetime = pd.to_datetime(historical_weather.datetime)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Data & Checking for NULL values","metadata":{}},{"cell_type":"code","source":"train.datetime = pd.to_datetime(train.datetime, format='%Y-%m-%d %H:%M:%S')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"https://www.kaggle.com/code/fabiendaniel/mapping-locations-and-county-codes/notebook  for county codes\nHere, they remove the 'maa' appendix from the county names. but is this really needed?","metadata":{}},{"cell_type":"markdown","source":"## Data Merging (now we merge everything to train)","metadata":{}},{"cell_type":"markdown","source":"### Merge Client","metadata":{}},{"cell_type":"code","source":"# append '_client' to merged columns\nclient.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge train and client\n\nmerged_df = pd.merge(train, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Gas Prices","metadata":{}},{"cell_type":"code","source":"# append _gas_prices to columns\ngas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge gas_prices\n\nmerged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Electricity Prices","metadata":{}},{"cell_type":"code","source":"# add time column for merging with electricity data\nmerged_df['time_of_day'] = merged_df['datetime'].dt.time\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge electricity prices\n# the prices are available hourly -> create new column with time \n\nelectricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n\n# append electricity_prices to column names\nelectricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Electricity Prices","metadata":{}},{"cell_type":"code","source":"# merge electricity_prices\n\nmerged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Historical Weather","metadata":{}},{"cell_type":"code","source":"# get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n\n# round lat and long to avoid mismatching due to different accuracy\nhistorical_weather.latitude = historical_weather.latitude.round(1)\nhistorical_weather.longitude = historical_weather.longitude.round(1)\n\nweather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\nweather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge historical weather to get counties\nmerged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n# get time of day\nmerged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n\n# aggregate by county and time (summarize weather stations for same county)\nmerged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n\n# append _hist_weather to column names\nmerged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge to merged_df\nmerged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Merge Forecast Weather","metadata":{}},{"cell_type":"code","source":"# forecast weather\n\n#round lat and long\nforecast_weather.latitude = forecast_weather.latitude.round(1)\nforecast_weather.longitude = forecast_weather.longitude.round(1)\n\n# merge to get counties\nmerged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n# merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n\n# # aggregate for duplicate locations\nmerged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n\n# append forecast_weather to column names\nmerged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Not needed anymore\n# add EET timezone to datetime, and handle daylight-savings\n#merged_df['datetime_localized'] = merged_df.datetime.dt.tz_localize('EET', ambiguous=True, nonexistent='shift_forward')\n\n# convert UTC timezone to EET timezone in forecast weather\n#merged_forecast_weather['datetime_EET']  = merged_forecast_weather.forecast_datetime.dt.tz_convert('EET')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# merge forecast_weather\nmerged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime', 'county'], right_on=['data_block_id', 'forecast_datetime', 'county'], how='left')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation","metadata":{}},{"cell_type":"code","source":"def split_datetime(data, col=\"datetime\"):\n    # What columns are of type datetime?\n    datetime_columns = data.select_dtypes(include='datetime64').columns\n    \n    for c in datetime_columns:\n        print(f\"Timezone for {c} is {data[c].dt.tz}\")\n\n    # Adding columns for date & time\n    data['year']    = data[col].dt.year\n    # data['quarter'] = data[col].dt.quarter\n    data['month']   = data[col].dt.month\n    data['week']    = data[col].dt.isocalendar().week\n    data['hour']    = data[col].dt.hour \n\n    data['day_of_year']  = data[col].dt.day_of_year\n    data['day_of_month'] = data[col].dt.day\n    data['day_of_week']  = data[col].dt.day_of_week\n\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mapping days of the week names and converting to categorical variable\nif 'day_of_week' in merged_df.columns:\n    weekday_map = {\n        0: 'Monday',\n        1: 'Tuesday',\n        2: 'Wednesday',\n        3: 'Thursday',\n        4: 'Friday',\n        5: 'Saturday',\n        6: 'Sunday'\n    }\n    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode categories to category datetype\n\nmerged_df['county'] = merged_df['county'].astype('category')\nmerged_df['product_type'] = merged_df['product_type'].astype('category')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy df for modelling\nmodel_df = merged_df\n\n# model is not able to handle object type\nmodel_df.drop('time_of_day', axis=1, inplace=True)\n\n# split datetime into meaningful features of int types\nmodel_df = split_datetime(model_df)\n\n# model is not able to handle datetime\nmodel_df = model_df.drop(model_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n\n# drop na from target\nmodel_df.dropna(subset=['target'], inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training & Model Building","metadata":{}},{"cell_type":"code","source":"#X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\ndrop_columns = [\n    'target',\n    'hours_ahead_forecast_weather',\n    'row_id',\n    'data_block_id',\n    'prediction_unit_id',\n    'longitude_hist_weather',\n    'longitude_forecast_weather',\n    'latitude_hist_weather',\n    'latitude_forecast_weather'\n]\n\n\nmodel = XGBRegressor(enable_categorical=True, max_depth=9, learning_rate=0.3)\nmodel.fit(model_df.drop(drop_columns, axis=1), model_df.target)\n\n# y_pred = bst.predict(X_test)\n\n## main optimisation metric\n# print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n# print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading Test Data / API","metadata":{}},{"cell_type":"code","source":"\ndef data_prep_data_block(test, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n\n    # Datatype conversion\n    client.date = pd.to_datetime(client.date)\n\n    ## Electricity Prices Data\n    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n\n    ## Forecast Weather Data\n    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n\n    ## Gas Prices Data\n    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n\n    ## Historical Weather Data\n    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n\n    ## Train Data & Checking for NULL values\n    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n\n    ## Data Merging (now we merge everything to test)\n    ### Merge Client\n    # append '_client' to merged columns\n    client.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]\n\n    # merge train and client\n    merged_df = pd.merge(test, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n\n    ### Merge Gas Prices\n    # append _gas_prices to columns\n    gas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]\n\n    # merge gas_prices\n    merged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n\n    ### Merge Electricity Prices\n    # add time column for merging with electricity data\n    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n\n    # Merge electricity prices\n    # the prices are available hourly -> create new column with time \n    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n\n    # append electricity_prices to column names\n    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n\n    ### Merge Electricity Prices\n    # merge electricity_prices\n    merged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n\n    ### Merge Historical Weather\n    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n\n    # round lat and long to avoid mismatching due to different accuracy\n    historical_weather.latitude = historical_weather.latitude.round(1)\n    historical_weather.longitude = historical_weather.longitude.round(1)\n\n    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\n    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n\n    # merge historical weather to get counties\n    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n    # get time of day\n    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n\n    # aggregate by county and time (summarize weather stations for same county)\n    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n\n    # append _hist_weather to column names\n    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n\n\n    # merge to merged_df\n    merged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')\n\n    ### Merge Forecast Weather\n    # forecast weather\n\n    #round lat and long\n    forecast_weather.latitude = forecast_weather.latitude.round(1)\n    forecast_weather.longitude = forecast_weather.longitude.round(1)\n\n    # merge to get counties\n    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n\n    # # aggregate for duplicate locations\n    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n\n    # append forecast_weather to column names\n    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n\n\n    # add EET timezone to datetime, and handle daylight-savings\n    merged_df['datetime_localized'] = merged_df.datetime.dt.tz_localize('EET', ambiguous=True, nonexistent='shift_forward')\n\n    # convert UTC timezone to EET timezone in forecast weather\n    merged_forecast_weather['datetime_EET']  = merged_forecast_weather.forecast_datetime.dt.tz_convert('EET')\n\n    # merge forecast_weather\n    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime_localized', 'county'], right_on=['data_block_id', 'datetime_EET', 'county'], how='left')\n\n    # mapping days of the week names and converting to categorical variable\n    if 'day_of_week' in merged_df.columns:\n        weekday_map = {\n            0: 'Monday',\n            1: 'Tuesday',\n            2: 'Wednesday',\n            3: 'Thursday',\n            4: 'Friday',\n            5: 'Saturday',\n            6: 'Sunday'\n        }\n        merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n    # encode categories to category datetype\n\n    merged_df['county'] = merged_df['county'].astype('category')\n    merged_df['product_type'] = merged_df['product_type'].astype('category')\n    \n    # model is not able to handle object type\n    merged_df.drop('time_of_day', axis=1, inplace=True)\n\n    # split datetime into meaningful features of int types\n    merged_df = split_datetime(merged_df)\n\n    # model is not able to handle datetime\n    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n\n    return merged_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef data_prep(test, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping):        \n\n    # Datatype conversion\n    client.date = pd.to_datetime(client.date)\n\n    ## Electricity Prices Data\n    electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n    electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n\n    ## Forecast Weather Data\n    forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n    forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n\n    ## Gas Prices Data\n    gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n    gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n\n    ## Historical Weather Data\n    historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n\n    ## Train Data & Checking for NULL values\n    test['datetime'] = pd.to_datetime(test.prediction_datetime, format='%Y-%m-%d %H:%M:%S')\n\n    ## Data Merging (now we merge everything to test)\n    ### Merge Client\n    # append '_client' to merged columns\n    client.columns = [f\"{column}_client\" if column not in ['county', 'is_business', 'product_type'] else column for column in client.columns]\n\n    # merge train and client\n    merged_df = pd.merge(test, client, on=['county', 'is_business', 'product_type'], how='left')\n\n    ### Merge Gas Prices\n\n    # merge gas_prices\n    merged_df[\"lowest_price_per_mwh_gas_prices\"] = gas_prices.lowest_price_per_mwh.min()\n    merged_df[\"highest_price_per_mwh_gas_prices\"] = gas_prices.highest_price_per_mwh.max()\n\n    ### Merge Electricity Prices\n    # add time column for merging with electricity data\n    merged_df['time_of_day'] = merged_df['datetime'].dt.time\n\n    # Merge electricity prices\n    # the prices are available hourly -> create new column with time \n    electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n\n    # append electricity_prices to column names\n    electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day'] else column for column in electricity_prices.columns]\n\n    ### Merge Electricity Prices\n    # merge electricity_prices\n    merged_df = pd.merge(merged_df, electricity_prices, on = ['time_of_day'], how='left')\n\n    ### Merge Historical Weather\n    # get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n\n    # round lat and long to avoid mismatching due to different accuracy\n    historical_weather.latitude = historical_weather.latitude.astype(\"float\").round(1)\n    historical_weather.longitude = historical_weather.longitude.astype(\"float\").round(1)\n    \n    weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.astype(\"float\").round(1)\n    weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.astype(\"float\").round(1)\n\n    # merge historical weather to get counties\n    merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n    # get time of day\n    merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n    \n    # aggregate by county and time (summarize weather stations for same county)\n    merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime']).mean(numeric_only=True).reset_index()\n    \n    # append _hist_weather to column names\n    merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day'] else column for column in merged_hist_weather.columns]\n\n    # merge to merged_df\n    merged_df = pd.merge(merged_df, merged_hist_weather, on=['time_of_day', 'county'], how='left')\n\n    ### Merge Forecast Weather\n    # forecast weather\n\n    #round lat and long\n    forecast_weather.latitude = forecast_weather.latitude.astype(\"float\").round(1)\n    forecast_weather.longitude = forecast_weather.longitude.astype(\"float\").round(1)\n\n    # merge to get counties\n    merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n    # merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n\n    # # aggregate for duplicate locations\n    merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime']).mean(numeric_only=True).reset_index()\n\n    # append forecast_weather to column names\n    merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime'] else column for column in merged_forecast_weather.columns]\n\n\n    # merge forecast_weather\n    merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['datetime', 'county'], right_on=['forecast_datetime', 'county'], how='left')\n    \n    # split datetime into meaningful features of int types\n    merged_df = split_datetime(merged_df)\n    \n    # mapping days of the week names and converting to categorical variable\n    if 'day_of_week' in merged_df.columns:\n        weekday_map = {\n            0: 'Monday',\n            1: 'Tuesday',\n            2: 'Wednesday',\n            3: 'Thursday',\n            4: 'Friday',\n            5: 'Saturday',\n            6: 'Sunday'\n        }\n    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')\n    # encode categories to category datetype\n\n    merged_df['county'] = merged_df['county'].astype('category')\n    merged_df['product_type'] = merged_df['product_type'].astype('category')\n    \n    # model is not able to handle object type\n    merged_df.drop('time_of_day', axis=1, inplace=True)\n\n    # model is not able to handle datetime\n    merged_df = merged_df.drop(merged_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]', \"object\"]).columns, axis=1)\n    \n    drop_columns = [\n    'hours_ahead_forecast_weather',\n    'row_id',\n    'prediction_unit_id',\n    'longitude_hist_weather',\n    'longitude_forecast_weather',\n    'latitude_hist_weather',\n    'latitude_forecast_weather',\n    'currently_scored'\n    ]\n    \n    merged_df.drop(drop_columns, axis=1, inplace=True)\n\n    return merged_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## prepare data frame","metadata":{}},{"cell_type":"code","source":"import enefit\n\n\nenv = enefit.make_env()\niter_test = env.iter_test()\ncounter = 0\nfor (test, revealed_targets, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n    if counter == 0:\n        print(test.head(3))\n        print(revealed_targets.head(3))\n        print(client.head(3))\n        print(historical_weather.head(3))\n        print(forecast_weather.head(3))\n        print(electricity_prices.head(3))\n        print(gas_prices.head(3))\n        print(sample_prediction.head(3))\n#    sample_prediction['target'] = 0\n    \n    prepped_df = data_prep(test, client, historical_weather,\n        forecast_weather, electricity_prices, gas_prices, sample_prediction, weather_station_to_county_mapping)\n    \n    sample_prediction[\"target\"] = model.predict(prepped_df)\n\n    env.predict(sample_prediction)\n    counter += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}