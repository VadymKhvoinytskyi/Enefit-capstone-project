{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"},{"sourceId":7426901,"sourceType":"datasetVersion","datasetId":4321565}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# crucial for import API interface and loading data\nON_KAGGLE: bool = True","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:00:54.349941Z","iopub.execute_input":"2024-01-18T10:00:54.350327Z","iopub.status.idle":"2024-01-18T10:00:54.356155Z","shell.execute_reply.started":"2024-01-18T10:00:54.350294Z","shell.execute_reply":"2024-01-18T10:00:54.354789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ON_KAGGLE:\n    import sys\n    sys.path.append('/kaggle/input/imports')\n    from helper_functions import split_datetime\n    from actpred_plot import plot_actual_vs_pred\n    from data_preprocessing import merge_data, remove_col\n    from feature_engineering import * # this is bad practice, call functions explicitly\nelse:\n    import sys\n    sys.path.append('../imports')\n    from helper_functions import split_datetime\n    from actpred_plot import plot_actual_vs_pred\n    from data_preprocessing import merge_data, remove_col\n    from feature_engineering import * # this is bad practice, call functions explicitly\n\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport plotly.express as px\n\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:00:54.358420Z","iopub.execute_input":"2024-01-18T10:00:54.358823Z","iopub.status.idle":"2024-01-18T10:00:56.670754Z","shell.execute_reply.started":"2024-01-18T10:00:54.358771Z","shell.execute_reply":"2024-01-18T10:00:56.669764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ON_KAGGLE:\n    DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\nelse:\n    DATA_DIR = \"../data/\"\n\n# Read CSVs and parse relevant date columns\ntrain = pd.read_csv(DATA_DIR + \"train.csv\")\nclient = pd.read_csv(DATA_DIR + \"client.csv\")\nhistorical_weather = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\nforecast_weather = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\nelectricity_prices = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\ngas_prices = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\nweather_station_to_county_mapping = pd.read_csv(DATA_DIR + 'weather_station_to_county_mapping.csv')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:00:56.671887Z","iopub.execute_input":"2024-01-18T10:00:56.672352Z","iopub.status.idle":"2024-01-18T10:01:21.776117Z","shell.execute_reply.started":"2024-01-18T10:00:56.672324Z","shell.execute_reply":"2024-01-18T10:01:21.774979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We merge all DataFrames \nmerged_df = merge_data(\n    train, client, historical_weather, forecast_weather, \n    electricity_prices, gas_prices, weather_station_to_county_mapping\n)\n\n# Drop all non needed columns (ids and timestamps)\nmerged_df = remove_col(merged_df, drop_row_id=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:21.778635Z","iopub.execute_input":"2024-01-18T10:01:21.778989Z","iopub.status.idle":"2024-01-18T10:01:34.158196Z","shell.execute_reply.started":"2024-01-18T10:01:21.778959Z","shell.execute_reply":"2024-01-18T10:01:34.157198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature engineering","metadata":{}},{"cell_type":"code","source":"merged_df = add_daylight_col(merged_df)\n\nmerged_df = add_capacity_col(merged_df)\n\nmerged_df = basic_improvements(merged_df)\n\nmerged_df = add_shifted_target(merged_df)\n\n# merged_df = add_public_holiday_col(merged_df)\n\n# merged_df = add_school_holiday_col(merged_df)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:34.162433Z","iopub.execute_input":"2024-01-18T10:01:34.163156Z","iopub.status.idle":"2024-01-18T10:01:38.470627Z","shell.execute_reply.started":"2024-01-18T10:01:34.163105Z","shell.execute_reply":"2024-01-18T10:01:38.469536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:38.471860Z","iopub.execute_input":"2024-01-18T10:01:38.472170Z","iopub.status.idle":"2024-01-18T10:01:38.480600Z","shell.execute_reply.started":"2024-01-18T10:01:38.472144Z","shell.execute_reply":"2024-01-18T10:01:38.479248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training & Model Building","metadata":{}},{"cell_type":"code","source":"drop_columns = [\n    'target', 'hours_ahead_forecast_weather',\n    'row_id', 'data_block_id', 'prediction_unit_id', \n    'longitude_hist_weather', 'latitude_hist_weather',\n    'longitude_forecast_weather', 'latitude_forecast_weather'\n]\n\nselected_fields = ['county', 'is_business', 'product_type', 'is_consumption',\n       'eic_count_client',\n       'surface_solar_radiation_downwards_forecast_weather',\n       'total_precipitation_forecast_weather', 'year', 'week', 'hour',\n       'day_of_year', 'day_of_week','daylight', 'capacity_per_eic',\n       'squared_capacity_client', 'sum_column', 'temp_dew', 'shifted_target'\n]","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:38.481855Z","iopub.execute_input":"2024-01-18T10:01:38.482220Z","iopub.status.idle":"2024-01-18T10:01:38.489660Z","shell.execute_reply.started":"2024-01-18T10:01:38.482189Z","shell.execute_reply":"2024-01-18T10:01:38.488470Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = merged_df.drop(['row_id', 'target'], axis=1)[selected_fields]\ny = merged_df.target\n                   \n\nmodel = XGBRegressor(enable_categorical=True, max_depth=6, learning_rate=0.3)\nmodel.fit(X, y)\n\n# y_pred = bst.predict(X_test)\n\n## main optimisation metric\n# print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n# print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:38.490922Z","iopub.execute_input":"2024-01-18T10:01:38.491282Z","iopub.status.idle":"2024-01-18T10:01:59.634834Z","shell.execute_reply.started":"2024-01-18T10:01:38.491241Z","shell.execute_reply":"2024-01-18T10:01:59.633717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(merged_df.drop(['row_id', 'target'], axis=1)[selected_fields])\n\n# main optimisation metric\nprint('Mean absolute error', mean_absolute_error(merged_df.target, y_pred))\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:01:59.637402Z","iopub.execute_input":"2024-01-18T10:01:59.637740Z","iopub.status.idle":"2024-01-18T10:02:05.737128Z","shell.execute_reply.started":"2024-01-18T10:01:59.637708Z","shell.execute_reply":"2024-01-18T10:02:05.736072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if ON_KAGGLE:\n    import enefit\nelse:\n    import sys\n    sys.path.append('../imports')\n    import public_timeseries_testing_util as enefit\n\n\n# copy of df before new data\nmerged_df['row_id'] = merged_df['row_id'].astype('int', errors='ignore')\n\nenv = enefit.make_env()\niter_test = env.iter_test()\n\ncounter = 0\nprevious_revealed_targets = pd.DataFrame()\nall_revealed_targets = pd.DataFrame()\n\nfor (test, revealed_targets, client, historical_weather,\n    forecast_weather, electricity_prices, gas_prices, sample_prediction) in iter_test:\n\n    \n    # if counter % 7 == 0:\n    #     model.fit(merged_df.drop(['row_id', 'target'], axis=1)[selected_fields], merged_df.target)\n        \n    #print(\"Iteration #:\", counter) \n\n    try: \n        # drop columns if target is na\n        model_df = merged_df.dropna(subset=['target'])\n    except:\n        print('some na targets were dropped')\n        # create alias anyway\n        model_df = merged_df\n\n    \n    if counter in range(0,5):\n        pass\n        # print(f'Test dataframe #{counter} \\n', test.head(3))\n        # print(f'Revealed targets dataframe #{counter} \\n', revealed_targets.head(3))\n        # print(revealed_targets.columns)\n        # print(f'Client dataframe #{counter} \\n', client.head(3))\n        # print(f'Historical weather dataframe #{counter} \\n', historical_weather.head(3))\n        # print(f'Forecast weather dataframe #{counter} \\n', forecast_weather.head(3))\n        # print(f'Electricity prices dataframe #{counter} \\n', electricity_prices.head(3))\n        # print(f'Gas prices dataframe #{counter} \\n', gas_prices.head(3))\n        # print(f'Sample prediction dataframe #{counter} \\n', sample_prediction.head(3))\n    \n    prepped_df = merge_data(\n        test, client, historical_weather, forecast_weather, \n        electricity_prices, gas_prices, weather_station_to_county_mapping\n    )\n\n    prepped_df = remove_col(prepped_df, drop_row_id=False)\n\n    # rename the target column of the revealed targets for merging\n    revealed_targets.rename(columns={'target' : 'shifted_target'}, inplace=True)\n    # introduce a hour column to merge on the prepped df\n    revealed_targets.datetime = pd.to_datetime(revealed_targets.datetime)\n    revealed_targets = split_datetime(revealed_targets)\n    # take only needed columns\n    sel_revealed_targets = revealed_targets[['county', 'is_business', 'product_type', 'is_consumption','hour','shifted_target']]\n    # merge the revealed targets as shifted target to the prepped_df\n    prepped_df = pd.merge(prepped_df, sel_revealed_targets, on= ['county', 'is_business', 'product_type', 'is_consumption', 'hour'], how='left')\n\n    # feature engineering\n    prepped_df = add_daylight_col(prepped_df)\n    prepped_df = add_capacity_col(prepped_df)\n    prepped_df = basic_improvements(prepped_df)\n\n    # prepped_df = add_public_holiday_col(prepped_df)\n    # prepped_df = add_school_holiday_col(prepped_df)\n\n    # print(merged_df.columns, '\\n', prepped_df.columns)\n\n    # pd.merge([merged_df, revealed_targets[['row_id', 'target']]], on=['row_id'], how='left', suffixes=('', '_revealed'))\n    # merged_df['target'] = merged_df[['target', 'target_revealed']].apply(lambda x: x.to_list()[0] if x.to_list()[0] else x.to_list()[1], axis=1)\n    # merged_df.drop('target_revealed', axis=1, inplace=True)\n    # leave out for now: using revealed targets as additional feature\n    # # bring new data to storage\n    # merged_df = pd.concat([merged_df, prepped_df], axis=0, ignore_index=True)\n    \n    # try:\n    #     # add revealed targets to data\n    #     revealed_targets = pd.concat([previous_revealed_targets, revealed_targets], axis=0, ignore_index=True)\n    #     targets_indexes = merged_df['row_id'][revealed_targets['row_id']].index\n    #     merged_df['target'].iloc[targets_indexes] = revealed_targets['target']\n    #     previous_revealed_targets = pd.DataFrame()\n    # except KeyError as e:\n    #     # store unused revealed targets for the next try\n    #     print('KeyError occurred')\n    #     print(e)\n    #     previous_revealed_targets = revealed_targets.copy()\n\n    sample_prediction['target'] = model.predict(prepped_df.drop('row_id', axis=1)[selected_fields])\n    sample_prediction['target'] = sample_prediction['target'].fillna(0).clip(0)\n    \n    # send predictions\n    env.predict(sample_prediction)    \n\n    counter += 1\n","metadata":{"execution":{"iopub.status.busy":"2024-01-18T10:02:05.738729Z","iopub.execute_input":"2024-01-18T10:02:05.739082Z","iopub.status.idle":"2024-01-18T10:02:08.767117Z","shell.execute_reply.started":"2024-01-18T10:02:05.739050Z","shell.execute_reply":"2024-01-18T10:02:08.765988Z"},"trusted":true},"execution_count":null,"outputs":[]}]}