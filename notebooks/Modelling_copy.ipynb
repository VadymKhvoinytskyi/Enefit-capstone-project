{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime(data, col=\"datetime\"):\n",
    "    # What columns are of type datetime?\n",
    "    datetime_columns = data.select_dtypes(include='datetime64').columns\n",
    "    \n",
    "    for c in datetime_columns:\n",
    "        print(f\"Timezone for {c} is {data[c].dt.tz}\")\n",
    "\n",
    "    # Adding columns for date & time\n",
    "    data['year']    = data[col].dt.year\n",
    "    # data['quarter'] = data[col].dt.quarter\n",
    "    data['month']   = data[col].dt.month\n",
    "    data['week']    = data[col].dt.isocalendar().week\n",
    "    data['hour']    = data[col].dt.hour \n",
    "\n",
    "    data['day_of_year']  = data[col].dt.day_of_year\n",
    "    data['day_of_month'] = data[col].dt.day\n",
    "    data['day_of_week']  = data[col].dt.day_of_week\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet('../data/merged_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping days of the week names and converting to categorical variable\n",
    "if 'day_of_week' in merged_df.columns:\n",
    "    weekday_map = {\n",
    "        0: 'Monday',\n",
    "        1: 'Tuesday',\n",
    "        2: 'Wednesday',\n",
    "        3: 'Thursday',\n",
    "        4: 'Friday',\n",
    "        5: 'Saturday',\n",
    "        6: 'Sunday'\n",
    "    }\n",
    "    merged_df['day_of_week'] = merged_df['day_of_week'].map(weekday_map).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categories to category datetype\n",
    "\n",
    "merged_df['county'] = merged_df['county'].astype('category')\n",
    "merged_df['product_type'] = merged_df['product_type'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workday vs weekend\n",
    "# estonian holidays\n",
    "# increasing in the capacity\n",
    "# aggregated weather of previous and/or future period\n",
    "# aggregated prices of previous period\n",
    "# target from previous year\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df for modelling\n",
    "model_df = merged_df\n",
    "\n",
    "# model is not able to handle object type\n",
    "model_df.drop('time_of_day', axis=1, inplace=True)\n",
    "\n",
    "# split datetime into meaningful features of int types\n",
    "model_df = split_datetime(model_df)\n",
    "\n",
    "# model is not able to handle datetime\n",
    "model_df = model_df.drop(model_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n",
    "\n",
    "# drop na from target\n",
    "model_df.dropna(subset=['target'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt gave us 50.75 mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['data_block_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split of old data to train and newer one to test\n",
    "\n",
    "Xy_train = model_df[model_df.data_block_id < 450]\n",
    "X_train = Xy_train.drop('target', axis=1)\n",
    "y_train = Xy_train.target\n",
    "\n",
    "Xy_test = model_df[model_df.data_block_id >= 450]\n",
    "X_test = Xy_test.drop('target', axis=1)\n",
    "y_test = Xy_test.target\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide by dates and use newer ones for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hours_ahead_forecast treated as important feature, probably smth to drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualisation\n",
    "- split by date\n",
    "- tweaking the parameters\n",
    "- drop some features\n",
    "- feature engineering\n",
    "- overfitting with traditional train_test_split?\n",
    "- try to models/ multiple_output/ other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df2 = model_df.copy()\n",
    "# model_df2.drop(['row_id', ])\n",
    "\n",
    "split_datablock = 300\n",
    "\n",
    "Xy_train = model_df[model_df.data_block_id < split_datablock]\n",
    "X_train = Xy_train.drop('target', axis=1)\n",
    "y_train = Xy_train.target\n",
    "\n",
    "Xy_test = model_df[model_df.data_block_id >= split_datablock]\n",
    "X_test = Xy_test.drop('target', axis=1)\n",
    "y_test = Xy_test.target\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = bst.predict(X_test)\n",
    "y_pred_train = bst.predict(X_train)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred_test))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=Xy_train.index, y=y_pred_train-y_train, color=Xy_train.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=Xy_test, x=Xy_test.index, y=y_pred_test-y_test, color=Xy_test.month, hover_data='day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_test['residual'] = y_pred_test-y_test\n",
    "\n",
    "Xy_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Xy_test.corr(numeric_only=True), annot=False, cmap='RdBu', center = 0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.figure(\n",
    "    figsize=(20, 20)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'residual'\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = Xy_test.select_dtypes(include=['number']).columns\n",
    "numeric_df = Xy_test[numeric_columns]\n",
    "numeric_df_cons = numeric_df[numeric_df['is_consumption'] == 1]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_cons.corr()\n",
    "\n",
    "# Select correlations based on the threshold\n",
    "threshold = 0.15\n",
    "significant_correlations = correlation_matrix[(correlation_matrix[target_column] > threshold) | (correlation_matrix[target_column] < -threshold)][target_column]\n",
    "\n",
    "# Plot a heatmap of the significant correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(significant_correlations.to_frame(), annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "plt.title(f'Significant Correlations with {target_column}, CONSUM ONLY (Threshold: {threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'residual'\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = Xy_test.select_dtypes(include=['number']).columns\n",
    "numeric_df = Xy_test[numeric_columns]\n",
    "numeric_df_cons = numeric_df[numeric_df['is_consumption'] == 0]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_cons.corr()\n",
    "\n",
    "# Select correlations based on the threshold\n",
    "threshold = 0.15\n",
    "significant_correlations = correlation_matrix[(correlation_matrix[target_column] > threshold) | (correlation_matrix[target_column] < -threshold)][target_column]\n",
    "\n",
    "# Plot a heatmap of the significant correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(significant_correlations.to_frame(), annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "plt.title(f'Significant Correlations with {target_column}, PRODUCTION ONLY (Threshold: {threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- residuals are bigger at the summer time, we quess because production is happening at this time\n",
    "\n",
    "- residuals on the test data have weekly pattern\n",
    "- last two month predicted very poorly\n",
    "\n",
    "- residuals are different depending on how we split our data \n",
    "- we see unexpalinable patterns in residuals\n",
    "- residuals for consumption and production correlate with different features\n",
    "\n",
    "- try residual analysis with traditional test_train_split\n",
    "\n",
    "- tweak the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))\n",
    "\n",
    "y_pred_test = bst.predict(X_test)\n",
    "y_pred_train = bst.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pretty much the same patterns with different train test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    'target',\n",
    "    'hours_ahead_forecast_weather',\n",
    "    'row_id',\n",
    "    'data_block_id', \n",
    "    'prediction_unit_id',\n",
    "    'longitude_hist_weather',\n",
    "    'longitude_forecast_weather',\n",
    "    'latitude_hist_weather',\n",
    "    'latitude_forecast_weather'\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop(drop_columns, axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=X_train.index, y=y_pred_train-y_train, color=X_train.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=X_test, x=X_test.index, y=y_pred_test-y_test, color=X_test.month, hover_data='day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Parameters\n",
    "\n",
    "What parameters can we tune?\n",
    "Source: https://xgboost.readthedocs.io/en/stable/parameter.html\n",
    "\n",
    "- `booster` [default: `gbtree`]: \n",
    "  - Description: Specifies the booster type to use.\n",
    "  - Options: \n",
    "    - `gbtree`: Uses tree-based models.\n",
    "    - `dart`: Similar to `gbtree`, but with dropout.\n",
    "    - `gblinear`: Uses linear functions.\n",
    "    \n",
    "- `eta` [default: `0.3`, alias: `learning_rate`]: \n",
    "  - Description: Step size shrinkage used in update to prevent overfitting. \n",
    "  - Range: `[0, 1]`\n",
    "\n",
    "- `max_depth` [default: `6`]: \n",
    "  - Description: Maximum depth of a tree. Increasing this value will make the model more complex and likely to overfit. \n",
    "  - Range: `[0, ∞]` (0 indicates no limit)\n",
    "\n",
    "- `subsample` [default: `1`]: \n",
    "  - Description: Subsample ratio of the training instances to prevent overfitting. \n",
    "  - Range: `(0, 1]`\n",
    "\n",
    "- `lambda` [default: `1`, alias: `reg_lambda`]: \n",
    "  - Description: L2 regularization term on weights. \n",
    "  - Range: `[0, ∞]`\n",
    "\n",
    "- `alpha` [default: `0`, alias: `reg_alpha`]: \n",
    "  - Description: L1 regularization term on weights. \n",
    "  - Range: `[0, ∞]`\n",
    "\n",
    "- `eval_metric` [default: according to objective]: \n",
    "  - Description: Evaluation metrics for validation data. \n",
    "  - Note: A default metric is assigned according to the objective (e.g., `rmse` for regression, `logloss` for classification). Users can add multiple evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch\n",
    "\n",
    "First only searching different tree level depths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning with gridsearch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define a range of hyperparameters to tune\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    #'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    #'n_estimators': [100, 200, 300, 500],\n",
    "    #'subsample': [0.7, 0.8, 0.9],\n",
    "}\n",
    "\n",
    "# Initialize the XGBRegressor with enable_categorical=True\n",
    "xgb_reg = XGBRegressor(enable_categorical=True)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and estimator\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking best model's MAE on test set\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking best model's MAE on train set\n",
    "\n",
    "y_pred = best_model.predict(X_train)\n",
    "\n",
    "# Calculate the Mean Absolute Error between the actual and predicted values\n",
    "mae = mean_absolute_error(y_train, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearch\n",
    "Different parameters are tuned, and df is split into consumption/production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomized search, but splitting the df into consumption/production, and choosing different parameters for tuning\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "drop_columns = [\n",
    "    'target',\n",
    "    'hours_ahead_forecast_weather',\n",
    "    'row_id',\n",
    "    'data_block_id',\n",
    "    'prediction_unit_id',\n",
    "    'longitude_hist_weather',\n",
    "    'longitude_forecast_weather',\n",
    "    'latitude_hist_weather',\n",
    "    'latitude_forecast_weather'\n",
    "]\n",
    "# max_depth 15 leads to overfitting\n",
    "params = {\n",
    "    'gamma': [0, 0.1, 1, 10],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_child_weight': [0, 1, 4, 8],\n",
    "    'lambda': [0, 0.01, 0.1, 1],\n",
    "    'num_parallel_tree': [1, 2, 3],\n",
    "}\n",
    "# consumption model\n",
    "X_train, X_test, y_train_cons,  y_test_cons = train_test_split(\n",
    "    model_df.drop(drop_columns, axis=1).query('is_consumption == 1'),\n",
    "    model_df.query('is_consumption == 1')['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "bst_cons = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(enable_categorical=True),\n",
    "    param_distributions=params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=10,\n",
    "    cv=2\n",
    ")\n",
    "bst_cons.fit(X_train, y_train_cons)\n",
    "y_pred_test_cons = bst_cons.predict(X_test)\n",
    "y_pred_train_cons = bst_cons.predict(X_train)\n",
    "print('Mean absolute error train consumption', mean_absolute_error(y_train_cons, y_pred_train_cons))\n",
    "print('Mean absolute error test consumption', mean_absolute_error(y_test_cons, y_pred_test_cons))\n",
    "# production model\n",
    "X_train, X_test, y_train_prod,  y_test_prod = train_test_split(\n",
    "    model_df.drop(drop_columns, axis=1).query('is_consumption == 0'),\n",
    "    model_df.query('is_consumption == 0')['target'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "bst_prod = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(enable_categorical=True),\n",
    "    param_distributions=params,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_iter=10,\n",
    "    cv=2\n",
    ")\n",
    "bst_prod.fit(X_train, y_train_prod)\n",
    "y_pred_test_prod = bst_prod.predict(X_test)\n",
    "y_pred_train_prod = bst_prod.predict(X_train)\n",
    "print('Mean absolute error train production', mean_absolute_error(y_train_prod, y_pred_train_prod))\n",
    "print('Mean absolute error test production', mean_absolute_error(y_test_prod, y_pred_test_prod))\n",
    "# overall score\n",
    "print(\n",
    "    'Mean absolute error train overall',\n",
    "    mean_absolute_error(\n",
    "          pd.concat([pd.Series(y_train_cons), pd.Series(y_train_prod)]),\n",
    "          pd.concat([pd.Series(y_pred_train_cons), pd.Series(y_pred_train_prod)])\n",
    "    )\n",
    ")\n",
    "print(\n",
    "    'Mean absolute error test overall',\n",
    "    mean_absolute_error(\n",
    "        pd.concat([pd.Series(y_test_cons), pd.Series(y_test_prod)]),\n",
    "        pd.concat([pd.Series(y_pred_test_cons), pd.Series(y_pred_test_prod)])\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is quite similar with the two hyperparameter search, max tree depth level is probably somewhere between 8 and 10.\n",
    "We need to validate our model on the test dataset, to see its reliability."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
