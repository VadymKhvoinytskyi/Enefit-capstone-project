{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetime(data, col=\"datetime\"):\n",
    "    # What columns are of type datetime?\n",
    "    datetime_columns = data.select_dtypes(include='datetime64').columns\n",
    "    \n",
    "    for c in datetime_columns:\n",
    "        print(f\"Timezone for {c} is {data[c].dt.tz}\")\n",
    "\n",
    "    # Adding columns for date & time\n",
    "    data['year']    = data[col].dt.year\n",
    "    # data['quarter'] = data[col].dt.quarter\n",
    "    data['month']   = data[col].dt.month\n",
    "    data['week']    = data[col].dt.isocalendar().week\n",
    "    data['hour']    = data[col].dt.hour \n",
    "\n",
    "    data['day_of_year']  = data[col].dt.day_of_year\n",
    "    data['day_of_month'] = data[col].dt.day\n",
    "    data['day_of_week']  = data[col].dt.day_of_week\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.read_parquet('../data/merged_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categories to category datetype\n",
    "\n",
    "merged_df['county'] = merged_df['county'].astype('category')\n",
    "merged_df['product_type'] = merged_df['product_type'].astype('category')\n",
    "merged_df['day_of_week'] = merged_df['day_of_week'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workday vs weekend\n",
    "# estonian holidays\n",
    "# increasing in the capacity\n",
    "# aggregated weather of previous and/or future period\n",
    "# aggregated prices of previous period\n",
    "# target from previous year\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy df for modelling\n",
    "model_df = merged_df\n",
    "\n",
    "# model is not able to handle object type\n",
    "model_df.drop('time_of_day', axis=1, inplace=True)\n",
    "\n",
    "# split datetime into meaningful features of int types\n",
    "model_df = split_datetime(model_df)\n",
    "\n",
    "# model is not able to handle datetime\n",
    "model_df = model_df.drop(model_df.select_dtypes(include=['datetime64[ns]', 'datetime64[ns, EET]']).columns, axis=1)\n",
    "\n",
    "# drop na from target\n",
    "model_df.dropna(subset=['target'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first attempt gave us 50.75 mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['data_block_id'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split of old data to train and newer one to test\n",
    "\n",
    "Xy_train = model_df[model_df.data_block_id < 450]\n",
    "X_train = Xy_train.drop('target', axis=1)\n",
    "y_train = Xy_train.target\n",
    "\n",
    "Xy_test = model_df[model_df.data_block_id >= 450]\n",
    "X_test = Xy_test.drop('target', axis=1)\n",
    "y_test = Xy_test.target\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide by dates and use newer ones for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)\n",
    "plt.title('Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hours_ahead_forecast treated as important feature, probably smth to drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- visualisation\n",
    "- split by date\n",
    "- tweaking the parameters\n",
    "- drop some features\n",
    "- feature engineering\n",
    "- overfitting with traditional train_test_split?\n",
    "- try to models/ multiple_output/ other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_df2 = model_df.copy()\n",
    "# model_df2.drop(['row_id', ])\n",
    "\n",
    "split_datablock = 300\n",
    "\n",
    "Xy_train = model_df[model_df.data_block_id < split_datablock]\n",
    "X_train = Xy_train.drop('target', axis=1)\n",
    "y_train = Xy_train.target\n",
    "\n",
    "Xy_test = model_df[model_df.data_block_id >= split_datablock]\n",
    "X_test = Xy_test.drop('target', axis=1)\n",
    "y_test = Xy_test.target\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = bst.predict(X_test)\n",
    "y_pred_train = bst.predict(X_train)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred_test))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=Xy_train.index, y=y_pred_train-y_train, color=Xy_train.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=Xy_test, x=Xy_test.index, y=y_pred_test-y_test, color=Xy_test.month, hover_data='day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_test['residual'] = y_pred_test-y_test\n",
    "\n",
    "Xy_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(Xy_test.corr(numeric_only=True), annot=False, cmap='RdBu', center = 0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.figure(\n",
    "    figsize=(20, 20)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'residual'\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = Xy_test.select_dtypes(include=['number']).columns\n",
    "numeric_df = Xy_test[numeric_columns]\n",
    "numeric_df_cons = numeric_df[numeric_df['is_consumption'] == 1]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_cons.corr()\n",
    "\n",
    "# Select correlations based on the threshold\n",
    "threshold = 0.15\n",
    "significant_correlations = correlation_matrix[(correlation_matrix[target_column] > threshold) | (correlation_matrix[target_column] < -threshold)][target_column]\n",
    "\n",
    "# Plot a heatmap of the significant correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(significant_correlations.to_frame(), annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "plt.title(f'Significant Correlations with {target_column}, CONSUM ONLY (Threshold: {threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'residual'\n",
    "\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = Xy_test.select_dtypes(include=['number']).columns\n",
    "numeric_df = Xy_test[numeric_columns]\n",
    "numeric_df_cons = numeric_df[numeric_df['is_consumption'] == 0]\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = numeric_df_cons.corr()\n",
    "\n",
    "# Select correlations based on the threshold\n",
    "threshold = 0.15\n",
    "significant_correlations = correlation_matrix[(correlation_matrix[target_column] > threshold) | (correlation_matrix[target_column] < -threshold)][target_column]\n",
    "\n",
    "# Plot a heatmap of the significant correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(significant_correlations.to_frame(), annot=True, cmap='coolwarm', fmt=\".2f\", cbar=False)\n",
    "plt.title(f'Significant Correlations with {target_column}, PRODUCTION ONLY (Threshold: {threshold})')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- residuals are bigger at the summer time, we quess because production is happening at this time\n",
    "\n",
    "- residuals on the test data have weekly pattern\n",
    "- last two month predicted very poorly\n",
    "\n",
    "- residuals are different depending on how we split our data \n",
    "- we see unexpalinable patterns in residuals\n",
    "- residuals for consumption and production correlate with different features\n",
    "\n",
    "- try residual analysis with traditional test_train_split\n",
    "\n",
    "- tweak the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop('target', axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))\n",
    "\n",
    "y_pred_test = bst.predict(X_test)\n",
    "y_pred_train = bst.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pretty much the same patterns with different train test splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = [\n",
    "    'target',\n",
    "    'hours_ahead_forecast_weather',\n",
    "    'row_id',\n",
    "    'data_block_id', \n",
    "    'prediction_unit_id',\n",
    "    'longitude_hist_weather',\n",
    "    'longitude_forecast_weather',\n",
    "    'latitude_hist_weather',\n",
    "    'latitude_forecast_weather'\n",
    "]\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(model_df.drop(drop_columns, axis=1), model_df['target'], test_size=0.3, random_state=0)\n",
    "\n",
    "bst = XGBRegressor(enable_categorical=True)\n",
    "bst.fit(X_train, y_train)\n",
    "y_pred = bst.predict(X_test)\n",
    "\n",
    "# main optimisation metric\n",
    "print('Mean absolute error test', mean_absolute_error(y_test, y_pred))\n",
    "print('Mean absolute error train', mean_absolute_error(y_train, bst.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=X_train.index, y=y_pred_train-y_train, color=X_train.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data_frame=X_test, x=X_test.index, y=y_pred_test-y_test, color=X_test.month, hover_data='day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
