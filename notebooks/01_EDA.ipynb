{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 'Living' Conclusion Gathering Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions Data Merge\n",
    "\n",
    "-  There seems to be no pattern in the null values in target column. This indicates we can drop these rows\n",
    "\n",
    "\n",
    "_County_\n",
    "- we think county 12 is weird (unknown location) and introduces NA values (not included in weather data)\n",
    "- maybe drop 12, but this may lead to other problems \n",
    "- county named 'unknown'\n",
    "- the forums say counties 16 and 0 may be weird\n",
    "\n",
    "_data_block_id_\n",
    "- we could reduce NaN and NaT values by excluding data_block_id 1 and 0 (beginning in data set)\n",
    "\n",
    "_Modelling / Time Series_\n",
    "- We are unsure about modelling (is time series model needed? maybe ARMA?) Forums suggest e.g. XGBoost\n",
    "\n",
    "\n",
    "## Conclusions EDA\n",
    "- consumption has noticeable affects by winter holidays\n",
    "- seems consumption is growing over time\n",
    "- county 0 is dominating, Tallinn located there\n",
    "- seems like temperature to production ratio changed last year\n",
    "- product_type 2 attract producers with small installed capacity thus low production\n",
    "- while product_type 3 attract the opposite cluster, producers with a lot of installed_capacity\n",
    "- Surface solar radiation seems to have a stronger correlation with target than direct_solar\n",
    "- There seems to be a 'split' around 6000 (unit?) daily mean target\n",
    "- We expected more businesses in the top-producers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "enefit_green = '#3f641a'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pd.read_csv('../data/client.csv')\n",
    "client.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "client.date = pd.to_datetime(client.date)\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking timeframe of the dataset\n",
    "display(min(client.date))\n",
    "display(max(client.date))\n",
    "display(client.data_block_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First day is '2021-09-01 00:00:00', last day is '2023-05-29 00:00:00'. There are 636 unique days, and data_block_id corresponds to date. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electricity Prices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_prices = pd.read_csv('../data/electricity_prices.csv')\n",
    "electricity_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "electricity_prices.forecast_date = pd.to_datetime(electricity_prices.forecast_date)\n",
    "electricity_prices.origin_date = pd.to_datetime(electricity_prices.origin_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique values in each column\n",
    "electricity_prices.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List unique forecast dates\n",
    "electricity_prices.forecast_date.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Electricity price forecast are available for each hour of the day (637 days * 24 hours = 15286 unique datetimes) (for 637 days, one day more than client data; somewhere there are 2h missing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather = pd.read_csv('../data/forecast_weather.csv')\n",
    "forecast_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "forecast_weather.origin_datetime = pd.to_datetime(forecast_weather.origin_datetime)\n",
    "forecast_weather.forecast_datetime = pd.to_datetime(forecast_weather.forecast_datetime)\n",
    "\n",
    "forecast_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking df columns\n",
    "forecast_weather.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check unique values by latitude and longitude\n",
    "forecast_weather.groupby(['latitude', 'longitude']).nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 112 unique combinations of lat and long (unique weather stations). \n",
    "So for each forecast_date, there are 112 observations (one from each station). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas Prices Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_prices = pd.read_csv('../data/gas_prices.csv')\n",
    "\n",
    "gas_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "gas_prices.forecast_date = pd.to_datetime(gas_prices.forecast_date)\n",
    "gas_prices.origin_date = pd.to_datetime(gas_prices.origin_date)\n",
    "\n",
    "gas_prices.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_weather = pd.read_csv('../data/historical_weather.csv')\n",
    "\n",
    "historical_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "historical_weather.datetime = pd.to_datetime(historical_weather.datetime)\n",
    "\n",
    "historical_weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Data & Checking for NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datatype conversion to datetime\n",
    "train.datetime = pd.to_datetime(train.datetime, format='%Y-%m-%d %H:%M:%S')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking null values within target\n",
    "train.groupby('is_consumption').agg({'target': lambda x: x.isnull().sum()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train.target.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be no pattern in the null values in target column. This indicates we can drop these rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We merge everything to train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.size, train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append '_client' to merged columns\n",
    "client.columns = [f\"{column}_client\" if column not in ['data_block_id', 'county', 'is_business', 'product_type'] else column for column in client.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge train and client\n",
    "\n",
    "merged_df = pd.merge(train, client, on=['data_block_id', 'county', 'is_business', 'product_type'], how='left')\n",
    "\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few/a lot null values, especially at the beginning and end of period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many eic counts per data_block_id?\n",
    "merged_df[merged_df.eic_count_client.isnull()].data_block_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do dates in train and client overlap? \n",
    "print(set(client.date_client.dt.date) ^ set(train.datetime.dt.date))\n",
    "print(set(train.data_block_id) ^ set(client.data_block_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_block(dbid):\n",
    "    display(\"TRAIN\", train[train['data_block_id'] == dbid])\n",
    "#     display(\"FORC WEATHER\", forecast_weather[forecast_weather['data_block_id'] == dbid])\n",
    "    display(\"CLIENT\", client[client['data_block_id'] == dbid])\n",
    "#     display(\"HIST WEATHER\", historical_weather[historical_weather['data_block_id'] == dbid])\n",
    "#     display(\"E PRICES\", electricity_prices[electricity_prices['data_block_id'] == dbid])\n",
    "#     display(\"G PRICES\", gas_prices[gas_prices['data_block_id'] == dbid])\n",
    "\n",
    "print_block(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with NULL values after merging. one source are the start and end dates, but we don't know whats happening in between and whether this is problematic.\n",
    "Maybe some client data is sporadically missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Gas Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gas_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append _gas_prices to columns\n",
    "gas_prices.columns = [f\"{column}_gas_prices\" if column != 'data_block_id' else column for column in gas_prices.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge gas_prices\n",
    "\n",
    "merged_df = pd.merge(merged_df, gas_prices, on=['data_block_id'], how='left')\n",
    "\n",
    "merged_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Electricity Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add time column for merging with electricity data\n",
    "merged_df['time_of_day'] = merged_df['datetime'].dt.time\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge electricity prices\n",
    "# the prices are available hourly -> create new column with time \n",
    "\n",
    "electricity_prices['time_of_day'] = electricity_prices.forecast_date.dt.time\n",
    "\n",
    "# append electricity_prices to column names\n",
    "electricity_prices.columns = [f\"{column}_electricity_prices\" if column not in ['time_of_day','data_block_id'] else column for column in electricity_prices.columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Electricity Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge electricity_prices\n",
    "\n",
    "merged_df = pd.merge(merged_df, electricity_prices, on = ['data_block_id', 'time_of_day'], how='left')\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Historical Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historic weather\n",
    "\n",
    "historical_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get county and county_name from weather_station_to_county_mapping (merge on latitude and longitude)\n",
    "weather_station_to_county_mapping = pd.read_csv('../data/weather_station_to_county_mapping.csv')\n",
    "\n",
    "# round lat and long to avoid mismatching due to different accuracy\n",
    "historical_weather.latitude = historical_weather.latitude.round(1)\n",
    "historical_weather.longitude = historical_weather.longitude.round(1)\n",
    "\n",
    "weather_station_to_county_mapping.latitude = weather_station_to_county_mapping.latitude.round(1)\n",
    "weather_station_to_county_mapping.longitude = weather_station_to_county_mapping.longitude.round(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge historical weather to get counties\n",
    "merged_hist_weather = pd.merge(historical_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n",
    "# get time of day\n",
    "merged_hist_weather['time_of_day'] = merged_hist_weather['datetime'].dt.time\n",
    "\n",
    "# aggregate by county and time (summarize weather stations for same county)\n",
    "merged_hist_weather = merged_hist_weather.groupby(['county', 'time_of_day', 'datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# append _hist_weather to column names\n",
    "merged_hist_weather.columns = [f\"{column}_hist_weather\" if column not in ['county', 'time_of_day','data_block_id'] else column for column in merged_hist_weather.columns]\n",
    "\n",
    "\n",
    "merged_hist_weather.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to merged_df\n",
    "merged_df = pd.merge(merged_df, merged_hist_weather, on=['data_block_id', 'time_of_day', 'county'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Forecast Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast weather\n",
    "\n",
    "#round lat and long\n",
    "forecast_weather.latitude = forecast_weather.latitude.round(1)\n",
    "forecast_weather.longitude = forecast_weather.longitude.round(1)\n",
    "\n",
    "# merge to get counties\n",
    "merged_forecast_weather = pd.merge(forecast_weather, weather_station_to_county_mapping, on=['latitude', 'longitude'], how='left')\n",
    "# merged_forecast_weather['time_of_day'] = merged_forecast_weather.\n",
    "\n",
    "# # aggregate for duplicate locations\n",
    "merged_forecast_weather = merged_forecast_weather.groupby(['county', 'forecast_datetime', 'data_block_id']).mean(numeric_only=True).reset_index()\n",
    "\n",
    "# append forecast_weather to column names\n",
    "merged_forecast_weather.columns = [f\"{column}_forecast_weather\" if column not in ['county', 'forecast_datetime','data_block_id'] else column for column in merged_forecast_weather.columns]\n",
    "\n",
    "\n",
    "merged_forecast_weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge forecast_weather\n",
    "merged_df = pd.merge(merged_df, merged_forecast_weather, left_on=['data_block_id', 'datetime', 'county'], right_on=['data_block_id', 'forecast_datetime', 'county'], how='left')\n",
    "\n",
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = merged_df.select_dtypes(include=[np.number])\n",
    "\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 1x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# Plot the first graph\n",
    "merged_df.groupby('county')['target'].mean().plot(kind='bar', ax=axes[0])\n",
    "axes[0].set_title('Average Consumption per County')\n",
    "axes[0].set_xlabel('County')\n",
    "axes[0].set_ylabel('Average Consumption')\n",
    "\n",
    "# Plot the second graph\n",
    "merged_df.groupby('product_type')['target'].mean().plot(kind='bar', ax=axes[1])\n",
    "axes[1].set_title('Average Consumption per Product type')\n",
    "axes[1].set_xlabel('Product type')\n",
    "axes[1].set_ylabel('Average Consumption')\n",
    "\n",
    "# Plot the third graph\n",
    "merged_df.groupby('is_business')['target'].mean().plot(kind='bar', ax=axes[2])\n",
    "axes[2].set_title('Average Consumption per Business')\n",
    "axes[2].set_xlabel('Business or not')\n",
    "axes[2].set_ylabel('Average Consumption')\n",
    "\n",
    "# Adjust layout to prevent clipping of titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the combined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(merged_df, x='datetime', y='target', color='is_business', title='Energy Consumption Over Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_consumption_by_county = merged_df.groupby(['county', 'is_business'])['target'].mean().reset_index()\n",
    "px.bar(avg_consumption_by_county, x='county', y='target', color='is_business', barmode='group', title='Average Energy Consumption by County and Business Type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for consumption\n",
    "consumption_df = merged_df[merged_df['is_consumption'] == True].copy()\n",
    "\n",
    "# Group by datetime and calculate the total consumption\n",
    "total_consumption = consumption_df.groupby('datetime')['target'].sum().reset_index()\n",
    "\n",
    "# Create a line chart for total consumption\n",
    "fig_consumption = px.line(total_consumption, x='datetime', y='target', title='Total Energy Consumption Over Time')\n",
    "\n",
    "# Update the line color\n",
    "fig_consumption.update_traces(line=dict(color='rgb(63, 100, 26)'))\n",
    "\n",
    "# Show the chart\n",
    "fig_consumption.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by datetime and calculate the total consumption\n",
    "average_consumption = consumption_df.groupby('datetime')['target'].mean().reset_index()\n",
    "\n",
    "# Create a line chart for total consumption\n",
    "fig_consumption = px.line(average_consumption, x='datetime', y='target', title='Average Energy Consumption Over Time')\n",
    "\n",
    "# Update the line color\n",
    "fig_consumption.update_traces(line=dict(color='rgb(63, 100, 26)'))\n",
    "\n",
    "# Show the chart\n",
    "fig_consumption.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'datetime' is in datetime format\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])\n",
    "\n",
    "# Extract year and month for aggregation\n",
    "merged_df['year_month'] = merged_df['datetime'].dt.to_period('M')\n",
    "\n",
    "# Filter for consumption and calculate total consumption per month\n",
    "consumption_df = merged_df[merged_df['is_consumption'] == True]\n",
    "monthly_consumption = consumption_df.groupby('year_month')['target'].mean().reset_index()\n",
    "\n",
    "# Filter for production and calculate total production per month\n",
    "production_df = merged_df[merged_df['is_consumption'] == False]\n",
    "monthly_production = production_df.groupby('year_month')['target'].mean().reset_index()\n",
    "\n",
    "# Assuming you have a capacity column, calculate monthly capacity\n",
    "monthly_capacity = merged_df.groupby('year_month')['installed_capacity_client'].mean().reset_index()\n",
    "\n",
    "# Convert 'year_month' to datetime for plotting\n",
    "monthly_consumption['year_month'] = monthly_consumption['year_month'].dt.to_timestamp()\n",
    "monthly_production['year_month'] = monthly_production['year_month'].dt.to_timestamp()\n",
    "monthly_capacity['year_month'] = monthly_capacity['year_month'].dt.to_timestamp()\n",
    "\n",
    "# Create a figure with both consumption and production\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# Add consumption trace to the primary y-axis\n",
    "fig.add_trace(go.Scatter(x=monthly_consumption['year_month'], y=monthly_consumption['target'], \n",
    "                         name='Consumption (mWh)', line=dict(color='rgb(63, 100, 26)', width=3)),\n",
    "              secondary_y=False)\n",
    "\n",
    "# Add production trace to the primary y-axis\n",
    "fig.add_trace(go.Scatter(x=monthly_production['year_month'], y=monthly_production['target'], \n",
    "                         name='Production (mWh)', line=dict(color='rgb(143, 188, 143)', dash='dash', width=3)),\n",
    "              secondary_y=False)\n",
    "\n",
    "# Add capacity trace to the secondary y-axis\n",
    "fig.add_trace(go.Scatter(x=monthly_capacity['year_month'], y=monthly_capacity['installed_capacity_client'], \n",
    "                         name='Capacity (kW)', line=dict(color='rgb(255, 0, 0)', width=3)),\n",
    "              secondary_y=True)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Energy Consumption, Production, and Capacity (monthly average)',\n",
    "    xaxis=dict(\n",
    "        title='Month',\n",
    "        showgrid=False  # Remove x-axis gridlines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Energy (consumption/production, mWh)',\n",
    "        titlefont=dict(color='rgb(0, 128, 0)'),  # Green color for x-axis title\n",
    "        tickfont=dict(color='rgb(0, 128, 0)'),       \n",
    "        showgrid=False  # Remove primary y-axis gridlines\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Capacity (kW)',\n",
    "        titlefont=dict(color='rgb(255, 0, 0)'),  # Red color for secondary y-axis title\n",
    "        tickfont=dict(color='rgb(255, 0, 0)'),      \n",
    "        showgrid=False  # Remove secondary y-axis gridlines\n",
    "    ),\n",
    "    plot_bgcolor='white'  # Set background color to white\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'datetime' is in datetime format\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])\n",
    "\n",
    "# Extract different time units\n",
    "merged_df['month'] = merged_df['datetime'].dt.month_name()\n",
    "merged_df['day_of_week'] = merged_df['datetime'].dt.day_name()\n",
    "# Ensure you have a 'time_of_day' column in merged_df\n",
    "# merged_df['time_of_day'] = ...\n",
    "\n",
    "# Define the correct order of months and days\n",
    "month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Prepare subplots\n",
    "fig = make_subplots(rows=3, cols=1, vertical_spacing=0.08,\n",
    "                    subplot_titles=(\"Average Energy Consumption and Production Trends by Month\",\n",
    "                                    \"Average Energy Consumption and Production Trends by Day of the Week\",\n",
    "                                    \"Average Energy Consumption and Production by Time of Day\"))\n",
    "\n",
    "# MONTHLY PLOT\n",
    "monthly_consumption = merged_df[merged_df['is_consumption'] == True].groupby('month')['target'].mean().reindex(month_order).reset_index()\n",
    "monthly_production = merged_df[merged_df['is_consumption'] == False].groupby('month')['target'].mean().reindex(month_order).reset_index()\n",
    "fig.add_trace(go.Bar(x=monthly_consumption['month'], y=monthly_consumption['target'], name='Consumption (mWh)', marker_color='rgb(63, 100, 26)'), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=monthly_production['month'], y=monthly_production['target'], name='Production (mWh)', marker_color='rgb(143, 188, 143)'), row=1, col=1)\n",
    "\n",
    "# DAILY PLOT\n",
    "daily_consumption = merged_df[merged_df['is_consumption'] == True].groupby('day_of_week')['target'].mean().reindex(day_order).reset_index()\n",
    "daily_production = merged_df[merged_df['is_consumption'] == False].groupby('day_of_week')['target'].mean().reindex(day_order).reset_index()\n",
    "fig.add_trace(go.Bar(x=daily_consumption['day_of_week'], y=daily_consumption['target'], name='Daily Consumption', marker_color='rgb(63, 100, 26)', showlegend=False), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=daily_production['day_of_week'], y=daily_production['target'], name='Daily Production', marker_color='rgb(143, 188, 143)', showlegend=False), row=2, col=1)\n",
    "\n",
    "# TIME OF DAY PLOT\n",
    "time_of_day_consumption = merged_df[merged_df['is_consumption'] == True].groupby('time_of_day')['target'].mean().reset_index()\n",
    "time_of_day_production = merged_df[merged_df['is_consumption'] == False].groupby('time_of_day')['target'].mean().reset_index()\n",
    "fig.add_trace(go.Bar(x=time_of_day_consumption['time_of_day'], y=time_of_day_consumption['target'], name='Time of Day Consumption', marker_color='rgb(63, 100, 26)', showlegend=False), row=3, col=1)\n",
    "fig.add_trace(go.Bar(x=time_of_day_production['time_of_day'], y=time_of_day_production['target'], name='Time of Day Production', marker_color='rgb(143, 188, 143)', showlegend=False), row=3, col=1)\n",
    "\n",
    "\n",
    "fig.update_layout(\n",
    "    height=1000,\n",
    "    xaxis=dict(showgrid=False),  # Remove x-axis gridlines for the first subplot\n",
    "    xaxis2=dict(showgrid=False), # Remove x-axis gridlines for the second subplot\n",
    "    xaxis3=dict(showgrid=False), # Remove x-axis gridlines for the third subplot\n",
    "    yaxis=dict(showgrid=False),  # Remove y-axis gridlines for the first subplot\n",
    "    yaxis2=dict(showgrid=False), # Remove y-axis gridlines for the second subplot\n",
    "    yaxis3=dict(showgrid=False), # Remove y-axis gridlines for the third subplot\n",
    "    plot_bgcolor='white'  # Set background color to white\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'datetime' is in datetime format\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])\n",
    "\n",
    "# Extract year and month for aggregation\n",
    "merged_df['year_month'] = merged_df['datetime'].dt.to_period('M')\n",
    "\n",
    "# Filter for consumption and production before grouping\n",
    "consumption_df = merged_df[merged_df['is_consumption'] == True]\n",
    "production_df = merged_df[merged_df['is_consumption'] == False]\n",
    "\n",
    "# Group by year_month for the different data points\n",
    "monthly_consumption = consumption_df.groupby('year_month')['target'].mean().reset_index()  # Unit: mWh\n",
    "monthly_production = production_df.groupby('year_month')['target'].mean().reset_index()  # Unit: mWh\n",
    "monthly_solar_radiation = merged_df.groupby('year_month')['direct_solar_radiation_hist_weather'].mean().reset_index()  # Unit: Wh/m²\n",
    "monthly_cloud_cover = merged_df.groupby('year_month')['cloudcover_total_hist_weather'].mean().reset_index()  # Unit: %\n",
    "\n",
    "# Convert 'year_month' to datetime for plotting\n",
    "monthly_consumption['year_month'] = monthly_consumption['year_month'].dt.to_timestamp()\n",
    "monthly_production['year_month'] = monthly_production['year_month'].dt.to_timestamp()\n",
    "monthly_solar_radiation['year_month'] = monthly_solar_radiation['year_month'].dt.to_timestamp()\n",
    "monthly_cloud_cover['year_month'] = monthly_cloud_cover['year_month'].dt.to_timestamp()\n",
    "\n",
    "# Create subplots with 2 rows\n",
    "fig = make_subplots(rows=2, cols=1, specs=[[{\"secondary_y\": True}], [{\"secondary_y\": True}]])\n",
    "\n",
    "# First chart traces (Solar Radiation)\n",
    "fig.add_trace(go.Scatter(x=monthly_consumption['year_month'], y=monthly_consumption['target'], \n",
    "                         name='Consumption (mWh)', line=dict(color='rgb(63, 100, 26)', width=3)),\n",
    "              row=1, col=1, secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=monthly_production['year_month'], y=monthly_production['target'], \n",
    "                         name='Production (mWh)', line=dict(color='rgb(143, 188, 143)', dash='dash', width=3)),\n",
    "              row=1, col=1, secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=monthly_solar_radiation['year_month'], y=monthly_solar_radiation['direct_solar_radiation_hist_weather'], \n",
    "                         name='Solar Radiation (Wh/m²)', line=dict(color='rgb(255, 215, 0)', width=3)), \n",
    "              row=1, col=1, secondary_y=True)\n",
    "\n",
    "# Second chart traces (Cloud Cover)\n",
    "fig.add_trace(go.Scatter(x=monthly_consumption['year_month'], y=monthly_consumption['target'], \n",
    "                         name='Consumption (mWh)', line=dict(color='rgb(63, 100, 26)', width=3), showlegend=False),\n",
    "              row=2, col=1, secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=monthly_production['year_month'], y=monthly_production['target'], \n",
    "                         name='Production (mWh)', line=dict(color='rgb(143, 188, 143)', dash='dash', width=3), showlegend=False),\n",
    "              row=2, col=1, secondary_y=False)\n",
    "fig.add_trace(go.Scatter(x=monthly_cloud_cover['year_month'], y=monthly_cloud_cover['cloudcover_total_hist_weather'], \n",
    "                         name='Cloud Cover (%)', line=dict(color='rgb(135, 206, 235)', width=3)),\n",
    "              row=2, col=1, secondary_y=True)\n",
    "\n",
    "# Update layout with separate y-axis titles for each subplot\n",
    "fig.update_layout(\n",
    "    title='Energy Consumption, Production, Solar Radiation, and Cloud Cover (monthly average)',\n",
    "    xaxis=dict(\n",
    "        title='Month',\n",
    "        showgrid=False  # Remove x-axis gridlines\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Energy (mWh)',\n",
    "        titlefont=dict(color='rgb(0, 128, 0)'),\n",
    "        tickfont=dict(color='rgb(0, 128, 0)'),\n",
    "        showgrid=False  # Remove y-axis gridlines for primary y-axis\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Solar Radiation (Wh/m²)',\n",
    "        titlefont=dict(color='rgb(255, 215, 0)'),\n",
    "        tickfont=dict(color='rgb(255, 215, 0)'),\n",
    "        showgrid=False  # Remove y-axis gridlines for secondary y-axis of first subplot\n",
    "    ),\n",
    "    yaxis3=dict(\n",
    "        title='Energy (mWh)',\n",
    "        titlefont=dict(color='rgb(0, 128, 0)'),\n",
    "        tickfont=dict(color='rgb(0, 128, 0)'),\n",
    "        showgrid=False  # Remove y-axis gridlines for primary y-axis of second subplot\n",
    "    ),\n",
    "    yaxis4=dict(\n",
    "        title='Cloud Cover (%)',\n",
    "        titlefont=dict(color='rgb(135, 206, 235)'),\n",
    "        tickfont=dict(color='rgb(135, 206, 235)'),\n",
    "        showgrid=False  # Remove y-axis gridlines for secondary y-axis of second subplot\n",
    "    ),\n",
    "    height=700,\n",
    "    width=1000,\n",
    "    plot_bgcolor='white'  # Set background color to white\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net Consumption\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_consumption = merged_df.query('is_consumption == 0')[[\"datetime\", \"target\"]].groupby(\"datetime\").sum().reset_index()\n",
    "net_consumption.rename({\"target\": \"production\"},axis=1, inplace=True)\n",
    "net_consumption[\"consumption\"] = merged_df.query('is_consumption == 1')[[\"datetime\", \"target\"]].groupby(\"datetime\").sum().reset_index()[\"target\"]\n",
    "net_consumption[\"net_consumption\"] =  net_consumption[\"consumption\"] - net_consumption[\"production\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_consumption[\"date\"] = net_consumption[\"datetime\"].dt.date\n",
    "net_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_consumption_per_day = net_consumption.groupby(\"date\")[[\"production\", \"consumption\", \"net_consumption\"]].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(net_consumption[\"datetime\"], net_consumption[\"net_consumption\"], c = enefit_green )\n",
    "plt.plot([net_consumption.datetime.min(), net_consumption.datetime.max()], [0,0], c = 'black')\n",
    "\n",
    "plt.fill_between(net_consumption[\"datetime\"], net_consumption.net_consumption.max(), facecolor='red', alpha=.5)\n",
    "plt.fill_between(net_consumption[\"datetime\"], net_consumption.net_consumption.min(), facecolor='green', alpha=.5)\n",
    "plt.title('The Hourly Net Consumption (consumption - production)')\n",
    "plt.ylabel(\"mwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = pd.Timestamp(2022, 9, 30, 23)\n",
    "first_date = pd.Timestamp(2022, 3, 1, 0)\n",
    "net_consumption_summer = net_consumption[(first_date <= net_consumption[\"datetime\"]) & (net_consumption[\"datetime\"] <= last_date)]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(net_consumption_summer[\"datetime\"], net_consumption_summer[\"net_consumption\"], c = enefit_green)\n",
    "plt.plot([net_consumption_summer.datetime.min(), net_consumption_summer.datetime.max()], [0,0], c = 'black')\n",
    "plt.fill_between(net_consumption_summer[\"datetime\"], net_consumption_summer.net_consumption.max(), facecolor='red', alpha=.5)\n",
    "plt.fill_between(net_consumption_summer[\"datetime\"], net_consumption_summer.net_consumption.min(), facecolor='green', alpha=.5)\n",
    "plt.title('The Hourly Net Consumptionin the sunny Period')\n",
    "plt.ylabel(\"mwh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(net_consumption_per_day[\"date\"], net_consumption_per_day[\"net_consumption\"] , c=enefit_green)\n",
    "plt.plot([net_consumption_per_day.date.min(), net_consumption_per_day.date.max()], [0,0])\n",
    "plt.title('Difference between production and consumption (production - consumption)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
